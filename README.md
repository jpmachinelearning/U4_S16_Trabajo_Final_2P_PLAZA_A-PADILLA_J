# An√°lisis de Opini√≥n en Repositorios Git

## üè´ Informaci√≥n Acad√©mica
**Universidad:** Universidad de Guayaquil
**Facultad:** Facultad de Ciencias Matem√°ticas y F√≠sicas
**Carrera:** Ciencia de Datos & IA
**Asignatura:** Procesamiento de Lenguaje Natural
**Proyecto:** Trabajo Parcial II - Observatorio de Opini√≥n y Salud del Proyecto

### üë• Integrantes:
| Nombre y Apellido | Rol / Contribuci√≥n |
| :--- | :--- |
| **JUAN PADILLA M.** | RF‚Äì01 Recolecci√≥n de datos, RF‚Äì02 Preprocesamiento, RF‚Äì03 Representaci√≥n (TF-IDF), RF‚Äì04 Sentimiento, RF‚Äì05 Temas |
| **ALEXANDER PLAZA J.** | RF‚Äì06 Similitud textual, Documentaci√≥n, An√°lisis de Hallazgos |

---

## üìñ 1. Contexto del Proyecto
En el desarrollo de software colaborativo, plataformas como GitHub y GitLab almacenan una gran cantidad de informaci√≥n textual en forma de issues, pull requests (PR) y comentarios. Estos textos reflejan problemas t√©cnicos, decisiones de dise√±o, nivel de satisfacci√≥n del equipo y momentos cr√≠ticos del proyecto.

El presente proyecto propone aplicar t√©cnicas cl√°sicas de **Procesamiento de Lenguaje Natural (PLN)** para analizar, clasificar y comparar dichos mensajes, con el fin de evaluar la opini√≥n expresada y la salud general del proyecto. El enfoque es exclusivamente anal√≠tico, prescindiendo del uso de modelos de Deep Learning, Transformers o agentes conversacionales.

## üéØ 2. Objetivos
### Objetivo General
Aplicar t√©cnicas cl√°sicas de PLN para analizar el sentimiento, los temas recurrentes y la similitud textual en mensajes de un repositorio Git, con el fin de generar un observatorio de opini√≥n y salud del proyecto.

### Objetivos Espec√≠ficos
1. **Recolecci√≥n**: Obtener mensajes reales (issues, PRs y comentarios) mediante APIs o archivos CSV.
2. **Preprocesado**: Aplicar t√©cnicas de limpieza y normalizaci√≥n cl√°sicas.
3. **Representaci√≥n**: Vectorizar los textos utilizando el modelo **TF‚ÄìIDF**.
4. **Sentimiento**: Clasificar mensajes en positivo, neutral o negativo mediante modelos supervisados.
5. **Categorizaci√≥n**: Identificar temas mediante agrupamiento (K-Means) o reglas de palabras clave.
6. **Similitud**: Implementar similitud coseno para encontrar mensajes similares.

## üìÇ 3. Estructura del Repositorio
data/: Contiene el dataset datos_github_proyecto_final.csv con los datos recolectados.
src/: C√≥digo fuente del proyecto.
    * eda_limpieza.py: Filtrado de ruido, bots e idioma.
    * preprocesado.py: Pipeline de normalizaci√≥n y tokenizaci√≥n.
README.md: Documentaci√≥n completa del proyecto.

## ‚öôÔ∏è 4. Pipeline de Procesamiento (Flujo de Trabajo)

El sistema sigue un flujo estrictamente secuencial para garantizar la calidad de los datos antes del an√°lisis:

### Fase I: EDA y Filtrado Cr√≠tico (eda)
Antes del preprocesado de PLN, los datos pasan por un filtrado de "calidad humana":
1. **Limpieza de Nulos**: Se eliminan registros sin contenido en el campo comentario.
2. **Filtro de Bots**: Se identifican y saltan mensajes generados autom√°ticamente (ej. ocabot, logs de servidores, comandos de merge).
3. **Detecci√≥n de Idioma y C√≥digo**: Se aplica una heur√≠stica de **frecuencia de Stopwords**. Si el texto no contiene palabras funcionales del espa√±ol (el, de, que, etc.) o tiene mayor proporci√≥n de palabras en ingl√©s, se descarta para evitar analizar c√≥digo de programaci√≥n o mensajes en otros idiomas.

### Fase II: Preprocesado de Texto (preprocesado)
Cada registro se trata como un "documento" dentro de una "colecci√≥n". El proceso incluye:
**Normalizaci√≥n**: Conversi√≥n total a min√∫sculas.
**Tokenizaci√≥n**: Divisi√≥n por palabras usando nltk.word_tokenize.
**POS Tagging**: Etiquetado gramatical para identificar y remover signos de puntuaci√≥n complejos.
**Limpieza de Caracteres**: Eliminaci√≥n manual de corchetes, guiones repetidos y s√≠mbolos especiales.
**Remoci√≥n de Stopwords**: Eliminaci√≥n de palabras vac√≠as del espa√±ol.
**Filtro Alfanum√©rico**: Se conservan solo tokens que contienen caracteres alfanum√©ricos, eliminando basura t√©cnica residual.

### Fase III: Representaci√≥n y An√°lisis (RF-03 a RF-06)
**Vectorizaci√≥n**: Uso de **TF-IDF** para transformar la colecci√≥n de documentos en matrices num√©ricas.
**Sentimiento**: Clasificaci√≥n mediante modelos cl√°sicos como Logistic Regression o Linear SVM.
**Similitud**: Implementaci√≥n de **Similitud Coseno** para comparar documentos entre s√≠.

## üõ†Ô∏è 5. Requerimientos Funcionales (Alcance)
**RF‚Äì01 Recolecci√≥n**: Conexi√≥n a API y almacenamiento en CSV.
**RF‚Äì02 Preprocesado**: Limpieza, normalizaci√≥n, remoci√≥n de puntuaci√≥n y stopwords.
**RF‚Äì03 Representaci√≥n**: Uso de modelo TF-IDF (unigramas/bigramas).
**RF‚Äì04 Sentimiento**: Clasificaci√≥n supervisada cl√°sica.
**RF‚Äì05 Identificaci√≥n de Temas**: Clustering (K-Means) o reglas basadas en palabras clave.
**RF‚Äì06 Similitud Textual**: C√°lculo de similitud coseno entre mensajes.
