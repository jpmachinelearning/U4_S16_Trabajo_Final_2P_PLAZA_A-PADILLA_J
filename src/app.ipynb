{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwaOmw9NQyfo1GxLoda7Cm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/blob/main/src/app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FvUeZvpmVC3P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4ecf63b-596b-4d46-fcd0-fa9dd018d8c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyGithub in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
            "Requirement already satisfied: pynacl>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from PyGithub) (1.6.2)\n",
            "Requirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.12/dist-packages (from PyGithub) (2.32.4)\n",
            "Requirement already satisfied: pyjwt>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (2.11.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from PyGithub) (4.15.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from PyGithub) (2.5.0)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (43.0.3)\n",
            "Requirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pynacl>=1.4.0->PyGithub) (2.0.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.14.0->PyGithub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.14.0->PyGithub) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.14.0->PyGithub) (2026.1.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=2.0.0->pynacl>=1.4.0->PyGithub) (3.0)\n",
            "Collecting es-core-news-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_lg-3.8.0/es_core_news_lg-3.8.0-py3-none-any.whl (568.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m568.0/568.0 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_lg')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.12/dist-packages (2.15.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ==========================================\n",
        "# 1. INSTALACION DE LIBRERIAS\n",
        "# ==========================================\n",
        "\n",
        "!pip install PyGithub\n",
        "!python -m spacy download es_core_news_lg\n",
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ================================================\n",
        "# 2. IMPORTACI√ìN DE LIBRERIAS Y VARIABLES GLOBALES\n",
        "# ================================================\n",
        "\n",
        "import emoji\n",
        "import re\n",
        "import spacy\n",
        "import nltk\n",
        "import datetime\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "from google.colab import files, userdata\n",
        "from github import Github, Auth, GithubException\n",
        "import os\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import joblib\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Descargas NLTK (ejecutar una vez)\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "STOP_ES = set(stopwords.words('spanish'))\n",
        "STOP_EN = set(stopwords.words('english'))\n",
        "\n",
        "nlp = spacy.blank(\"es\")\n",
        "nlp2 = spacy.load(\"es_core_news_lg\")\n",
        "\n",
        "if \"sentencizer\" not in nlp.pipe_names:\n",
        "    nlp.add_pipe(\"sentencizer\")\n",
        "\n",
        "INLINE_CODE = re.compile(r'`[^`]+`')\n",
        "FENCED_CODE = re.compile(r'```(.+?)```', re.DOTALL)\n",
        "CODE_KEYWORDS = re.compile(r'\\b(def|class|import|from|return|console\\.log|printf|#include|std::|->|=>)\\b')\n",
        "BRACES_SEMICOLON = re.compile(r'[{};=<>]')\n",
        "IMG_TAG = re.compile(r'<img\\b[^>]*>', re.IGNORECASE)\n",
        "HTML_TAG = re.compile(r'<\\/?\\w+[^>]*>', re.IGNORECASE)\n",
        "URL_LARGE = re.compile(r'https?://\\S{30,}', re.IGNORECASE)\n",
        "ASSET_DOMAINS = re.compile(r'(github\\.com|githubusercontent\\.com|assets/|cdn\\.)', re.IGNORECASE)\n",
        "\n",
        "MAPEO_LEMAS = {\n",
        "  \"hi\": \"hola\",\n",
        "  \"Ademas\": \"adem√°s\",\n",
        "  \"ademas\": \"adem√°s\",\n",
        "  \"qutarir\": \"quitar\",\n",
        "  \"qutacer\": \"quitar\",\n",
        "  \"qutaria\": \"quitar\",\n",
        "  \"qutar√≠a\": \"quitar\",\n",
        "  \"a√±adiais\": \"a√±adir\",\n",
        "  \"v√°lir\": \"v√°lido\",\n",
        "  \"gracia\": \"gracias\",\n",
        "  \"modul\": \"m√≥dulo\",\n",
        "  \"finar\": \"final\",\n",
        "  \"somar\": \"sumar\",\n",
        "  \"deveria\": \"deber\",\n",
        "  \"dever√≠a\": \"deber\",\n",
        "  \"estaria\": \"estar\",\n",
        "  \"est√°r√≠a\": \"estar\",\n",
        "  \"configurancion\": \"configuraci√≥n\",\n",
        "  \"temrinos\": \"t√©rminos\",\n",
        "  \"desp√©s\": \"despu√©s\",\n",
        "  \"propois\": \"propios\",\n",
        "  \"v√°lir\": \"valer\",\n",
        "  \"viudedad\": \"viudedad\",\n",
        "  \"reav\": \"revisar\",\n",
        "  \"qeu\": \"que\",\n",
        "  \"pusistar\": \"pusiste\",\n",
        "  \"modificaco\": \"modificado\",\n",
        "  \"desc√°rgatar\": \"descargar\",\n",
        "  \"fuentir\": \"fuente\",\n",
        "  \"invoizar\": \"facturar\",\n",
        "  \"informacion\": \"informaci√≥n\",\n",
        "  \"subsana\": \"subsanar\",\n",
        "  \"eskema\": \"esquema\",\n",
        "  }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HANBfslKmC-J",
        "outputId": "6651fbcb-bf84-4d20-858b-cfca9766a77e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ===============================================\n",
        "# 3. CONEXI√ìN Y CLONADO DE REPOSITORIO DE GITHUB\n",
        "# ===============================================\n",
        "\n",
        "try:\n",
        "    TOKEN = userdata.get('GITHUB_TOKEN')\n",
        "    USER_GITHUB = \"jpmachinelearning\"\n",
        "    EMAIL_GITHUB = userdata.get('MY_EMAIL')\n",
        "\n",
        "    # Configurar identidad global de Git de una vez\n",
        "    !git config --global user.email \"{EMAIL_GITHUB}\"\n",
        "    !git config --global user.name \"{USER_GITHUB}\"\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"‚ùå Error: Crea el secreto 'GITHUB_TOKEN' en el panel lateral.\")\n",
        "\n",
        "# --- RUTAS Y NOMBRES ---\n",
        "DEST_REPO_NAME = 'U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J'\n",
        "REPO_URL = f\"https://{TOKEN}@github.com/{USER_GITHUB}/{DEST_REPO_NAME}.git\"\n",
        "ruta_repositorio_local = f\"/content/{DEST_REPO_NAME}\"\n",
        "ruta_local_data = os.path.join(ruta_repositorio_local, 'data')\n",
        "\n",
        "# Inicializar archivo de log (sobrescribe en cada ejecuci√≥n)\n",
        "ruta_log_file_txt = os.path.join(ruta_local_data, 'log_file.txt')\n",
        "with open(ruta_log_file_txt, 'w', encoding='utf-8') as _log_init:\n",
        "    _log_init.write(f\"Log iniciado: {datetime.datetime.utcnow().isoformat()} UTC\\n\")\n",
        "    _log_init.write(\"=\"*120 + \"\\n\\n\")\n",
        "\n",
        "print(f\"üìù Archivo de log redireccionado a: {ruta_log_file_txt}\")\n",
        "\n",
        "# --- FUNCI√ìN DE UTILIDAD PARA CLONADO/SINCRO ---\n",
        "def inicializar_repositorio():\n",
        "    %cd /content/\n",
        "    if not os.path.exists(DEST_REPO_NAME):\n",
        "        print(f\"üöÄ Clonando {DEST_REPO_NAME}...\")\n",
        "        !git clone {REPO_URL}\n",
        "    else:\n",
        "        print(f\"üîÑ Sincronizando repositorio...\")\n",
        "        %cd {DEST_REPO_NAME}\n",
        "        !git pull origin main\n",
        "        %cd /content/\n",
        "    os.makedirs(os.path.dirname(ruta_local_data), exist_ok=True)\n",
        "    print(f\"üìÇ Carpeta de datos lista en: {os.path.dirname(ruta_local_data)}\")\n",
        "\n",
        "# Inicializar carpeta si no existe\n",
        "inicializar_repositorio()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbdFWfFBYb8P",
        "outputId": "a7aace63-a3c4-4910-fa51-8de4dddcbb88"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2949984326.py:25: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  _log_init.write(f\"Log iniciado: {datetime.datetime.utcnow().isoformat()} UTC\\n\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìù Archivo de log redireccionado a: /content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data/log_file.txt\n",
            "/content\n",
            "üîÑ Sincronizando repositorio...\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 4 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (4/4), 1.84 KiB | 145.00 KiB/s, done.\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "   585685b..6a5295b  main       -> origin/main\n",
            "Updating 585685b..6a5295b\n",
            "Fast-forward\n",
            " src/app.ipynb | 288 \u001b[32m++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m------------------------\u001b[m\n",
            " 1 file changed, 169 insertions(+), 119 deletions(-)\n",
            "/content\n",
            "üìÇ Carpeta de datos lista en: /content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================================\n",
        "# 4. FUNCIONES\n",
        "# ==========================================\n",
        "\n",
        "### ---  Funciones de para prepeocesado ---\n",
        "\n",
        "def ensure_text_input(corpus):\n",
        "    if isinstance(corpus, str):\n",
        "        return corpus\n",
        "    # pandas Series o DataFrame cell\n",
        "    if pd is not None and isinstance(corpus, pd.Series):\n",
        "        # eliminar NaN y convertir a str\n",
        "        parts = [str(x) for x in corpus.dropna().astype(str).tolist()]\n",
        "        return \"\\n\\n\".join(parts)\n",
        "    # lista/tupla de strings\n",
        "    if isinstance(corpus, (list, tuple)):\n",
        "        parts = [str(x) for x in corpus if x is not None]\n",
        "        return \"\\n\\n\".join(parts)\n",
        "    # fallback: intentar str()\n",
        "    return str(corpus)\n",
        "\n",
        "\n",
        "def apply_mapeo_and_simple_grammar(text, corrections=None):\n",
        "    \"\"\"\n",
        "    Aplica MAPEO_LEMAS sobre tokens y corrige patrones gramaticales puntuales.\n",
        "    Si se pasa 'corrections' (lista), a√±ade tuplas (original, reemplazo).\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str) or not text:\n",
        "        return text\n",
        "    # 1) Normalizar tokens simples usando MAPEO_LEMAS (mantener espacios)\n",
        "    def replace_token_match(m):\n",
        "        tok_orig = m.group(0)\n",
        "        tok = tok_orig.lower()\n",
        "        tok_repl = MAPEO_LEMAS.get(tok, tok)\n",
        "        # registrar si hubo cambio real y se pas√≥ lista\n",
        "        if corrections is not None and tok_repl != tok:\n",
        "            corrections.append((tok_orig, tok_repl))\n",
        "        return tok_repl\n",
        "    pattern = re.compile(r'\\b(' + '|'.join(re.escape(k) for k in MAPEO_LEMAS.keys()) + r')\\b', flags=re.IGNORECASE)\n",
        "    text = pattern.sub(lambda m: replace_token_match(m), text)\n",
        "    # 2) Reglas gramaticales puntuales (ejemplos seguros y no intrusivos)\n",
        "    #    - \"ning√∫n excepci√≥n\" -> \"ninguna excepci√≥n\"\n",
        "    def replace_ningun_excepcion(m):\n",
        "        orig = m.group(0)\n",
        "        repl = 'ninguna excepci√≥n'\n",
        "        if corrections is not None:\n",
        "            corrections.append((orig, repl))\n",
        "        return repl\n",
        "    text = re.sub(r'\\bning√∫n\\s+excepci√≥n\\b', replace_ningun_excepcion, text, flags=re.IGNORECASE)\n",
        "    #    - corregir dobles espacios\n",
        "    text = re.sub(r'\\s{2,}', ' ', text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "# --- Sustituciones finales robustas: URLs -> 'url' y n√∫meros -> 'num' ---\n",
        "def apply_placeholders_preserve_punct(text: str, replacements=None) -> str:\n",
        "    if not isinstance(text, str) or not text:\n",
        "        return text\n",
        "    # URL pattern (prioriza detecci√≥n de URL completa)\n",
        "    url_pattern = re.compile(r'(?P<prefix>[\\(\\[\\{<\"\\']?)'r'(?P<url>(?:https?[:/]{0,3}|//|www\\.)'r'[A-Za-z0-9\\-]+'r'(?:\\.[A-Za-z0-9\\-]+)+'r'(?:[\\/?#][^\\s\\)\\]\\}\\>,.;:!?\"\\']*)?)'r'(?P<suffix>[\\)\\]\\}>,.;:!?\"\\']*)',flags=re.IGNORECASE)\n",
        "    def _url_sub(m):\n",
        "        orig = m.group('url')\n",
        "        if replacements is not None:\n",
        "            replacements.append((orig, 'url'))\n",
        "        return f\"{m.group('prefix')} {m.group('suffix')}\"\n",
        "    text = url_pattern.sub(_url_sub, text)\n",
        "    # N√∫mero puro: preservar prefijo/sufijo de puntuaci√≥n\n",
        "    number_pattern = re.compile(r'(?<![A-Za-z0-9])'r'(?P<prefix>[\\(\\[\\{<\"\\']?)'r'(?P<num>\\d+)'r'(?P<suffix>[\\)\\]\\}>,.;:!?\"\\']?)'r'(?![A-Za-z0-9])')\n",
        "    def _num_sub(m):\n",
        "        orig = m.group('num')\n",
        "        if replacements is not None:\n",
        "            replacements.append((orig, 'num'))\n",
        "        return f\"{m.group('prefix')} {m.group('suffix')}\"\n",
        "\n",
        "\n",
        "    text = number_pattern.sub(_num_sub, text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def preprocesado(doc):\n",
        "  # Pipeline del prepocesado: normalizaci√≥n -> traducci√≥n de emoji -> clasificador (doble revisi√≥n 'und') / eliminaci√≥n segmentos 'en', 'und' y 'code' ->\n",
        "  # elimanci√≥n de typos -> cambio de numeros por placeholder 'num' y sitio web por 'url' ->\n",
        "  # eliminaci√≥n signos de puntuaci√≥n -> tokenizaci√≥n -> eliminaci√≥n de stopwords -> lematizaci√≥n\n",
        "\n",
        "\n",
        "  ### Normalizaci√≥n\n",
        "  #Normalizar entrada a texto (maneja None, NaN, Series, listas, etc.)\n",
        "  doc = ensure_text_input(doc) # Si queda vac√≠o, devolver resultado vac√≠o y log m√≠nimo\n",
        "  if not doc or str(doc).strip() == \"\":\n",
        "    return \"\", [[\"input_empty\"]]\n",
        "  doc = doc.lower()\n",
        "\n",
        "\n",
        "  ### Traducci√≥n de emoji\n",
        "  #doc = emoji.demojize(doc, language='es').replace(':', '').replace('_', ' ')\n",
        "\n",
        "  # 1. Comprobamos si existen emojis en el documento mediante un condicional\n",
        "  if emoji.emoji_count(doc) > 0:\n",
        "\n",
        "      # 2. Definimos una funci√≥n interna (callback) que solo procesa el emoji hallado\n",
        "      def procesar_emoji_individual(chars, data_dict):\n",
        "          # Traducimos el emoji a su nombre en espa√±ol (ej: :cara_sonriente:)\n",
        "          nombre_emoji = emoji.demojize(chars, language='es')\n",
        "\n",
        "          # 3. Limpiamos los signos SOLO del nombre generado por demojize.\n",
        "          # Esto permite que \"cara_sonriente\" pase a ser \"cara sonriente\"\n",
        "          # para que el an√°lisis de sentimiento/TF-IDF lo entienda mejor,\n",
        "          # pero sin afectar a las URLs del resto del documento.\n",
        "          nombre_limpio = nombre_emoji.replace(':', '').replace('_', ' ')\n",
        "\n",
        "          # Devolvemos el texto con espacios para que no se pegue a otras palabras\n",
        "          return f\" {nombre_limpio} \"\n",
        "\n",
        "      # 4. Aplicamos el reemplazo selectivo\n",
        "      doc = emoji.replace_emoji(doc, replace=procesar_emoji_individual)\n",
        "\n",
        "  ### Elimanci√≥n de typos\n",
        "  ortho_corrections = []\n",
        "  doc = apply_mapeo_and_simple_grammar(doc, corrections=ortho_corrections)\n",
        "\n",
        "\n",
        "  ### Clasificador (doble revision 'und') / eliminacion segmentos 'en', 'und' y 'code'\n",
        "  def looks_like_code_line(line):\n",
        "      if INLINE_CODE.search(line):\n",
        "          return True\n",
        "      if FENCED_CODE.search(line):\n",
        "          return True\n",
        "      if IMG_TAG.search(line) or HTML_TAG.search(line):\n",
        "          return True\n",
        "      if URL_LARGE.search(line) and ASSET_DOMAINS.search(line):\n",
        "          return True\n",
        "      if CODE_KEYWORDS.search(line):\n",
        "          return True\n",
        "      non_alpha = sum(1 for ch in line if not ch.isalpha() and not ch.isspace())\n",
        "      if len(line) > 0 and (non_alpha / len(line)) > 0.25:\n",
        "          return True\n",
        "      if BRACES_SEMICOLON.search(line):\n",
        "          return True\n",
        "      return False\n",
        "\n",
        "  def split_by_blank_and_guess(segment):\n",
        "      parts = []\n",
        "      groups = re.split(r'\\n\\s*\\n', segment)\n",
        "      for g in groups:\n",
        "          lines = [ln for ln in g.splitlines() if ln.strip() != \"\"]\n",
        "          if not lines:\n",
        "              continue\n",
        "          #FORZAR code si hay etiquetas img/html o URLs de assets en las l√≠neas\n",
        "          # (requiere que IMG_TAG, HTML_TAG, URL_LARGE, ASSET_DOMAINS est√©n definidos globalmente)\n",
        "          if any(IMG_TAG.search(ln) or (URL_LARGE.search(ln) and ASSET_DOMAINS.search(ln)) or HTML_TAG.search(ln) for ln in lines):\n",
        "              parts.append(('code', \"\\n\".join(lines)))\n",
        "              continue\n",
        "          code_like_count = sum(1 for ln in lines if looks_like_code_line(ln) or ln.startswith('    ') or ln.startswith('\\t'))\n",
        "          prop = code_like_count / len(lines)\n",
        "          if prop >= 0.4:\n",
        "              code_lines = []\n",
        "              text_lines = []\n",
        "              for ln in lines:\n",
        "                  tokens = [t.lower() for t in word_tokenize(ln) if t.isalpha()]\n",
        "                  if len(tokens) >= 2:\n",
        "                      es_count = sum(1 for t in tokens if t in STOP_ES)\n",
        "                      if es_count / len(tokens) >= 0.25 or re.search(r'[√°√©√≠√≥√∫√±√Å√â√ç√ì√ö√ë]', ln):\n",
        "                          text_lines.append(ln)\n",
        "                          continue\n",
        "                  code_lines.append(ln)\n",
        "              if code_lines:\n",
        "                  parts.append(('code', \"\\n\".join(code_lines)))\n",
        "              if text_lines:\n",
        "                  parts.append(('text', \"\\n\".join(text_lines)))\n",
        "          else:\n",
        "              parts.append(('text', \"\\n\".join(lines)))\n",
        "      return parts\n",
        "\n",
        "  def split_into_blocks_by_indentation_and_fences(corpus):\n",
        "      \"\"\"\n",
        "      Acepta corpus de cualquier tipo; primero normaliza a string.\n",
        "      Extrae fenced code y agrupa el resto por bloques separados por l√≠nea en blanco.\n",
        "      \"\"\"\n",
        "      text = ensure_text_input(corpus)\n",
        "      # --- NORMALIZACI√ìN ADICIONAL: convertir separadores en \"punto y aparte\" ---\n",
        "      # 1) [sep] o [ sep] -> punto y salto de l√≠nea doble\n",
        "      text = re.sub(r'\\[\\s*sep\\s*\\]', '.\\n\\n', text, flags=re.IGNORECASE)\n",
        "      # 2) punto seguido (\". \") -> punto y salto de l√≠nea doble\n",
        "      text = re.sub(r'\\.\\s+', '.\\n\\n', text)\n",
        "      # ------------------------------------------------------------------------\n",
        "      blocks = []\n",
        "      cursor = 0\n",
        "      for m in FENCED_CODE.finditer(text):\n",
        "          pre = text[cursor:m.start()]\n",
        "          if pre.strip():\n",
        "              blocks.extend(split_by_blank_and_guess(pre))\n",
        "          code_block = m.group(0)\n",
        "          blocks.append(('code', code_block))\n",
        "          cursor = m.end()\n",
        "      tail = text[cursor:]\n",
        "      if tail.strip():\n",
        "          blocks.extend(split_by_blank_and_guess(tail))\n",
        "      return blocks\n",
        "\n",
        "  def detect_language_by_stopwords(text, min_tokens=1):\n",
        "      \"\"\"\n",
        "      Detecta 'es', 'en', 'bilingual' o 'und'.\n",
        "      Ajustes:\n",
        "        - tokenizaci√≥n robusta (quita prefijos/sufijos no alfab√©ticos)\n",
        "        - lista blanca ampliada (incluye 'finde')\n",
        "        - heur√≠stica para frases cortas sin stopwords\n",
        "        - filtra tokens de longitud 1 al contar stopwords\n",
        "        - prioriza 'es' cuando la se√±al espa√±ola es claramente mayor\n",
        "        - condici√≥n 'bilingual' m√°s estricta\n",
        "      \"\"\"\n",
        "      txt_stripped = text.strip()\n",
        "      # caso puntual muy corto (ej. \"Gracias\" o \"Gracias.\")\n",
        "      if txt_stripped.lower() in {'gracias', 'gracias.'}:\n",
        "          return 'es'\n",
        "      # tokenizaci√≥n robusta: limpiar prefijos/sufijos no alfab√©ticos\n",
        "      raw_tokens = word_tokenize(text)\n",
        "      tokens = []\n",
        "      for t in raw_tokens:\n",
        "          t_clean = re.sub(r'^[^A-Za-z√Å√â√ç√ì√ö√ë√°√©√≠√≥√∫√±]+|[^A-Za-z√Å√â√ç√ì√ö√ë√°√©√≠√≥√∫√±]+$', '', t)\n",
        "          if t_clean:\n",
        "              tokens.append(t_clean.lower())\n",
        "      # lista blanca para singletons y sufijos t√≠picos\n",
        "      SPANISH_SINGLETONS = {'gracias','hola','adjunto','captura','saludos','ok','listo','si','no','vale','finde'}\n",
        "      SPANISH_SUFFIXES = ('ci√≥n','dad','mente','ado','ada','ico','ica','oso','osa')\n",
        "      # 1) single token common spanish\n",
        "      if len(tokens) == 1:\n",
        "          single = tokens[0]\n",
        "          if single in SPANISH_SINGLETONS or re.search(r'[√°√©√≠√≥√∫√±]', single):\n",
        "              return 'es'\n",
        "      # si hay pocos tokens, aplicar heur√≠sticas adicionales (fallback temprano)\n",
        "      if len(tokens) < min_tokens:\n",
        "          if re.search(r'[√°√©√≠√≥√∫√±√Å√â√ç√ì√ö√ë]', text):\n",
        "              return 'es'\n",
        "          low = text.lower()\n",
        "          for kw in ('que','para','con','por','como','ejemplo','funci√≥n','usar','gracias','alguna','novedad','adjunto','captura','finde'):\n",
        "              if kw in low:\n",
        "                  return 'es'\n",
        "          return 'und'\n",
        "      # filtrar tokens muy cortos para el conteo (evita ruido de 'a', 'I', etc.)\n",
        "      tokens_for_count = [t for t in tokens if len(t) > 1]\n",
        "      if not tokens_for_count:\n",
        "          tokens_for_count = tokens\n",
        "      # conteo de stopwords usando tokens filtrados\n",
        "      es_count = sum(1 for t in tokens_for_count if t in STOP_ES)\n",
        "      en_count = sum(1 for t in tokens_for_count if t in STOP_EN)\n",
        "      es_ratio = es_count / len(tokens_for_count) if tokens_for_count else 0\n",
        "      en_ratio = en_count / len(tokens_for_count) if tokens_for_count else 0\n",
        "      # --- NUEVA REGLA PUNTUAL: preferir 'en' si hay URL/asset y se√±al m√≠nima de ingl√©s ---\n",
        "      if (ASSET_DOMAINS.search(text) or re.search(r'https?://', text)) and en_ratio >= 0.05:\n",
        "          return 'en'\n",
        "      # ------------------------------------------------------------------------------\n",
        "      # 2) heur√≠stica para frases cortas sin stopwords (casos como \"Adjunto captura.\")\n",
        "      if len(tokens) >= 2 and es_count == 0 and en_count == 0:\n",
        "          # aceptar si hay acento en alguno, sufijo t√≠pico espa√±ol o palabra en whitelist\n",
        "          if any(re.search(r'[√°√©√≠√≥√∫√±]', t) for t in tokens):\n",
        "              return 'es'\n",
        "          if any(t in SPANISH_SINGLETONS for t in tokens):\n",
        "              return 'es'\n",
        "          if any(t.endswith(SPANISH_SUFFIXES) for t in tokens):\n",
        "              return 'es'\n",
        "          # si no hay evidencia clara de ingl√©s, asumir espa√±ol de forma conservadora\n",
        "          return 'es'\n",
        "      # Priorizar espa√±ol o ingl√©s si la se√±al es claramente mayor\n",
        "      if es_ratio > en_ratio and es_ratio >= 0.12:\n",
        "          return 'es'\n",
        "      if en_ratio > es_ratio and en_ratio >= 0.12:\n",
        "          return 'en'\n",
        "      # marcar bilingual solo si hay evidencia s√≥lida en ambos idiomas\n",
        "      if len(tokens_for_count) >= 3 and es_ratio >= 0.12 and en_ratio >= 0.12:\n",
        "          return 'bilingual'\n",
        "      # decisi√≥n por proporci√≥n de stopwords (criterio secundario)\n",
        "      if es_ratio >= 0.12 and es_ratio > en_ratio:\n",
        "          return 'es'\n",
        "      if en_ratio >= 0.12 and en_ratio > es_ratio:\n",
        "          return 'en'\n",
        "      # fallback final por acentos\n",
        "      if re.search(r'[√°√©√≠√≥√∫√±√Å√â√ç√ì√ö√ë]', text):\n",
        "          return 'es'\n",
        "      return 'und'\n",
        "\n",
        "  def classify_and_extract_strict(corpus, recursividad, window=3):\n",
        "      \"\"\"\n",
        "      Versi√≥n ajustada:\n",
        "        - Imprime la salida (category, spanish_with_code, code_blocks, items, details)\n",
        "          antes de devolver el resultado.\n",
        "        - Reconstruye (recomposici√≥n) un nuevo texto que solo incluye secciones\n",
        "          consideradas espa√±olas (lang == 'es' o 'bilingual').\n",
        "        - Para elementos eliminados (lang in {'und','code','en'} o type == 'code'),\n",
        "          imprime \"Dato borrado:\" seguido del item.\n",
        "      \"\"\"\n",
        "      log = []\n",
        "      text = ensure_text_input(corpus)\n",
        "      blocks = split_into_blocks_by_indentation_and_fences(text)\n",
        "      items = []\n",
        "      for typ, content in blocks:\n",
        "          if typ == 'code':\n",
        "              m = FENCED_CODE.search(content)\n",
        "              inner = m.group(1) if m else content\n",
        "              items.append({'type': 'code', 'text': inner.strip(), 'lang': 'code'})\n",
        "          else:\n",
        "              doc = nlp(content)\n",
        "              for sent in doc.sents:\n",
        "                  s = sent.text.strip()\n",
        "                  if not s:\n",
        "                      continue\n",
        "                  lang = detect_language_by_stopwords(s)\n",
        "                  items.append({'type': 'text', 'text': s, 'lang': lang})\n",
        "      total = len(items)\n",
        "      code_count = sum(1 for it in items if it['type'] == 'code')\n",
        "      es_count = sum(1 for it in items if it['lang'] == 'es')\n",
        "      en_count = sum(1 for it in items if it['lang'] == 'en')\n",
        "      if total == 0:\n",
        "          category = \"texto ingles 100%\"\n",
        "      else:\n",
        "          prop_code = code_count / total\n",
        "          prop_es = es_count / total\n",
        "          prop_en = en_count / total\n",
        "          if prop_code >= 0.95:\n",
        "              category = \"texto codigo de programacion 100%\"\n",
        "          elif prop_es >= 0.95 and code_count == 0:\n",
        "              category = \"texto espa√±ol 100%\"\n",
        "          elif prop_en >= 0.95 and code_count == 0:\n",
        "              category = \"texto ingles 100%\"\n",
        "          elif prop_es > 0.5 and code_count > 0:\n",
        "              category = \"texto espa√±ol + codigo de programacion\"\n",
        "          else:\n",
        "              category = \"texto bilingue\"\n",
        "      spanish_related = []\n",
        "      for i, it in enumerate(items):\n",
        "          if it['type'] == 'code':\n",
        "              start = max(0, i - window)\n",
        "              end = min(len(items) - 1, i + window)\n",
        "              for j in range(start, end + 1):\n",
        "                  cand = items[j]\n",
        "                  if cand['type'] == 'text' and cand['lang'] == 'es':\n",
        "                      spanish_related.append(cand['text'])\n",
        "      if not spanish_related:\n",
        "          tech_keywords = {'funci√≥n','variable','clase','m√©todo','archivo','ejemplo','par√°metro','argumento','instalar','importar','usar'}\n",
        "          for it in items:\n",
        "              if it['type'] == 'text' and it['lang'] == 'es':\n",
        "                  tokens = set(t.lower() for t in word_tokenize(it['text']) if t.isalpha())\n",
        "                  if tokens & tech_keywords or re.search(r'[√°√©√≠√≥√∫√±]', it['text']):\n",
        "                      spanish_related.append(it['text'])\n",
        "      seen = set()\n",
        "      spanish_with_code = []\n",
        "      for s in spanish_related:\n",
        "          if s not in seen:\n",
        "              seen.add(s)\n",
        "              spanish_with_code.append(s)\n",
        "      code_blocks = [it['text'] for it in items if it['type'] == 'code']\n",
        "      for it in items:\n",
        "          log.append(f\"{it['type']} | {it['lang']} | {it['text']}\")\n",
        "      log.append(f\"Detalles: total_items: {total} | code_items: {code_count} | spanish_items: {es_count} | english_items: {en_count}\")\n",
        "      # --- Recomposici√≥n del texto original manteniendo solo espa√±ol ---\n",
        "      # Incluir items cuya etiqueta de idioma sea 'es' o 'bilingual' y que no sean c√≥digo.\n",
        "      recomposed_parts = []\n",
        "      for it in items:\n",
        "        # condici√≥n para conservar: tipo text y lang es o bilingual\n",
        "        if recursividad:\n",
        "          if it['type'] == 'text' and it['lang'] in {'es', 'bilingual'}:\n",
        "            recomposed_parts.append(it['text'])\n",
        "          else:\n",
        "            log.append(f\"Dato borrado: {it['type']} | {it['lang']} | {it['text']}\")\n",
        "        elif it['type'] == 'text' and it['lang'] in {'es', 'bilingual', 'und'}:\n",
        "          recomposed_parts.append(it['text'])\n",
        "        else:\n",
        "          # imprimir mensaje de borrado para los elementos no conservados\n",
        "          log.append(f\"Dato borrado: {it['type']} | {it['lang']} | {it['text']}\")\n",
        "      # unir con un espacio entre oraciones/secciones\n",
        "      recomposed_text = \" \".join(p.strip() for p in recomposed_parts if p.strip())\n",
        "      log.append(f\"recomposed_text: {recomposed_text}\")\n",
        "      # devolver la recomposici√≥n y el log\n",
        "      return recomposed_text, log\n",
        "  logs_for_flat =[]\n",
        "  res1, log1 = classify_and_extract_strict(doc, recursividad=False)\n",
        "  logs_for_flat.append(log1)\n",
        "  res2, log2 = classify_and_extract_strict(res1, recursividad=True)\n",
        "  res2 = (res2 or \"\").strip()\n",
        "  # normalizar res2 (recomposed_text)\n",
        "  if not res2:\n",
        "    res2 = \"\"\n",
        "\n",
        "\n",
        "  ### Cambio de numeros por placeholder 'num' y sitio web por 'url' (desactivado)\n",
        "  placeholder_changes = []\n",
        "  res2 = apply_placeholders_preserve_punct(res2, replacements=placeholder_changes)\n",
        "\n",
        "\n",
        "  if log2:\n",
        "    logs_for_flat.append(\"__Recursividad__\")\n",
        "  logs_for_flat.append(log2)\n",
        "  # aplanar (flatten) y asegurar que cada elemento sea string y sin saltos iniciales/finales\n",
        "  logs = []\n",
        "  for part in logs_for_flat:\n",
        "      if isinstance(part, (list, tuple)):\n",
        "          for line in part:\n",
        "              logs.append(str(line).strip())\n",
        "      else:\n",
        "          logs.append(str(part).strip())\n",
        "  # eliminar entradas vac√≠as si las hubiera\n",
        "  logs = [l for l in logs if l]\n",
        "  # --- Escribir logs, cambios placeholders y ortogr√°ficos en archivo log_file.txt ---\n",
        "  timestamp = datetime.datetime.utcnow().isoformat()\n",
        "  try:\n",
        "      #ruta_log_final = os.path.join(ruta_local_data, 'log_file.txt')\n",
        "      with open(ruta_log_file_txt, 'a', encoding='utf-8') as lf:\n",
        "          # si hay logs generales ya calculados (variable logs existente), escribirlos\n",
        "          if logs:\n",
        "              lf.write(f\"# Entrada procesada {timestamp} UTC\\n\")\n",
        "              for line in logs:\n",
        "                  lf.write(line + \"\\n\")\n",
        "              lf.write(\"\\n\")\n",
        "          # 1) Correcciones ortogr√°ficas (si las hay)\n",
        "          if ortho_corrections:\n",
        "              lf.write(f\"__Corrector Ortogr√°fico__{timestamp}\\n\")\n",
        "              for orig, repl in ortho_corrections:\n",
        "                  lf.write(f\"'{orig}' se corrige por '{repl}'\\n\")\n",
        "              lf.write(\"\\n\")\n",
        "          # 2) Cambios por placeholders (si los hay)\n",
        "          if placeholder_changes:\n",
        "              lf.write(f\"__Cambio por Placeholder__{timestamp}\\n\")\n",
        "              for orig, repl in placeholder_changes:\n",
        "                  lf.write(f\"'{orig}' se cambio por '{repl}'\\n\")\n",
        "              lf.write(\"\\n\")\n",
        "  except Exception:\n",
        "      # no interrumpir el pipeline por errores de logging\n",
        "      pass\n",
        "\n",
        "  def limpieza_selectiva_tecnica(doc):\n",
        "      \"\"\"\n",
        "      Limpia signos de puntuaci√≥n respetando:\n",
        "      - URLs completas (https://www.aeat.es)\n",
        "      - Versiones (16.0, 17.0.1)\n",
        "      - Guiones entre texto/n√∫meros (l10n-es, factura-e, v18-beta)\n",
        "      \"\"\"\n",
        "      # 1. Normalizaci√≥n de espacios y saltos de l√≠nea\n",
        "      doc = doc.replace('\\\\n', ' ').replace('\\n', ' ')\n",
        "      # 2. PROTEGER URLs\n",
        "      urls = re.findall(r'https?://\\S+', doc)\n",
        "      for i, url in enumerate(urls):\n",
        "          doc = doc.replace(url, f' TOKEN_URL_{i} ')\n",
        "      # 3. PROTEGER VERSIONES (Puntos entre n√∫meros)\n",
        "      versiones = re.findall(r'\\d+\\.\\d+(?:\\.\\d+)*', doc)\n",
        "      for i, ver in enumerate(versiones):\n",
        "          doc = doc.replace(ver, f' TOKEN_VER_{i} ')\n",
        "      # 4. LIMPIEZA DE SIGNOS (Excepto el guion por ahora)\n",
        "      # Borramos: ¬° ! ¬ø ? [ ] ( ) { } | # * , ; : \" ' ¬ª ¬´ @\n",
        "      signos_a_borrar = r'[¬°!¬ø?\\[\\](){}|#*,\\;:\\\"\\'¬ª¬´@]'\n",
        "      doc = re.sub(signos_a_borrar, ' ', doc)\n",
        "      # 5. TRATAMIENTO DE PUNTOS Y GUIONES RESTANTES\n",
        "      # Borrar puntos que no protegimos (puntos al final de frase)\n",
        "      doc = re.sub(r'\\.', ' ', doc)\n",
        "      # Borrar guiones SOLO si NO est√°n entre letras o n√∫meros\n",
        "      # (Borra guiones decorativos pero mantiene l10n-es o factura-e)\n",
        "      doc = re.sub(r'(?<![a-zA-Z0-9])-|-(?![a-zA-Z0-9])', ' ', doc)\n",
        "      # 6. RESTAURAR URLs Y VERSIONES\n",
        "      for i, ver in enumerate(versiones):\n",
        "          doc = doc.replace(f' TOKEN_VER_{i} ', f' {ver} ')\n",
        "      for i, url in enumerate(urls):\n",
        "          doc = doc.replace(f' TOKEN_URL_{i} ', f' {url} ')\n",
        "      # 7. COLAPSAR ESPACIOS\n",
        "      doc = re.sub(r'\\s+', ' ', doc).strip()\n",
        "      return doc\n",
        "\n",
        "\n",
        "  ### Eliminaci√≥n signos de puntuaci√≥n\n",
        "  def limpieza_selectiva_tecnica(doc):\n",
        "      \"\"\"\n",
        "      Mantiene puntos en todo el texto (para extensiones y URLs).\n",
        "      Mantiene dos puntos (:) SOLO en URLs.\n",
        "      Elimina el resto de s√≠mbolos t√©cnicos innecesarios.\n",
        "      \"\"\"\n",
        "      if not doc:\n",
        "          return \"\"\n",
        "      # 1. Normalizaci√≥n de espacios y reparaci√≥n de protocolo\n",
        "      doc = doc.replace('\\\\n', ' ').replace('\\n', ' ')\n",
        "      # Reparar URLs mal escritas (ej: https// -> https://)\n",
        "      doc = re.sub(r'(https?)(//)', r'\\1:\\2', doc)\n",
        "      # 2. PROTEGER URLs (Capa de Seguridad M√°xima)\n",
        "      # Esto captura la URL completa con sus : / y .\n",
        "      urls = re.findall(r'https?://\\S+', doc)\n",
        "      for i, url in enumerate(urls):\n",
        "          doc = doc.replace(url, f' TOKEN_URL_{i} ')\n",
        "      # 3. PROTEGER N√öMEROS T√âCNICOS (Versiones y porcentajes)\n",
        "      # Ej: 16.0, 1.0.1, 10%\n",
        "      nums_tecnicos = re.findall(r'\\d+[.,]\\d+(?:\\.\\d+)*%?', doc)\n",
        "      for i, nt in enumerate(nums_tecnicos):\n",
        "          doc = doc.replace(nt, f' TOKEN_NUM_{i} ')\n",
        "      # 4. LIMPIEZA SELECTIVA DE S√çMBOLOS\n",
        "      # Eliminamos los dos puntos (:) y la barra (/) aqu√≠ porque las URLs ya est√°n protegidas.\n",
        "      # MANTENEMOS el punto (.) por instrucci√≥n directa.\n",
        "      signos_a_borrar = r'[:/=<>\\\\[\\]{}()|#@*+;\\\"\\'¬´¬ª`‚Ä¢]'\n",
        "      doc = re.sub(signos_a_borrar, ' ', doc)\n",
        "      # 5. TRATAMIENTO DE CONECTORES (Guion y Guion Bajo)\n",
        "      # Se mantienen solo si est√°n entre letras o n√∫meros (ej: l10n_es, factura-e)\n",
        "      # Se borran si son decorativos o est√°n sueltos.\n",
        "      doc = re.sub(r'(?<![a-zA-Z0-9])[-_]|[-_](?![a-zA-Z0-9])', ' ', doc)\n",
        "      # 6. RESTAURACI√ìN\n",
        "      # Devolvemos las URLs y N√∫meros a su sitio original intactos\n",
        "      for i, nt in enumerate(nums_tecnicos):\n",
        "          doc = doc.replace(f' TOKEN_NUM_{i} ', f' {nt} ')\n",
        "      for i, url in enumerate(urls):\n",
        "          doc = doc.replace(f' TOKEN_URL_{i} ', f' {url} ')\n",
        "      # 7. COLAPSAR ESPACIOS\n",
        "      doc = re.sub(r'\\s+', ' ', doc).strip()\n",
        "      return doc\n",
        "\n",
        "  #Llamado de funci√≥n para quitar selectivamente signos de puntuaci√≥n\n",
        "  doc = limpieza_selectiva_tecnica(res2)\n",
        "\n",
        "\n",
        "  ### Tokenizaci√≥n\n",
        "  doc = nlp2(doc)\n",
        "\n",
        "\n",
        "  ### Eliminaci√≥n de stopwords\n",
        "  doc = [token for token in doc if not token.is_stop and not token.is_punct and not token.is_space] #[token for token in doc if not token.is_stop]\n",
        "\n",
        "\n",
        "  ### Lematizaci√≥n\n",
        "  doc = \" \".join([token.lemma_ for token in doc])\n",
        "\n",
        "  return doc\n",
        "\n",
        "\n",
        "### --- FUNCI√ìN GLOBAL DE CARGA ---\n",
        "def sincronizar_con_github(repo_path, lista_archivos, mensaje_commit):\n",
        "    try:\n",
        "        if not os.path.exists(repo_path):\n",
        "            raise Exception(f\"La ruta del repositorio {repo_path} no existe.\")\n",
        "        %cd {repo_path}\n",
        "\n",
        "        # 1. Preparar archivos (Staging)\n",
        "        archivos_a√±adidos = 0\n",
        "        for archivo in lista_archivos:\n",
        "            # Verificamos que el archivo exista antes de intentar a√±adirlo\n",
        "            if os.path.exists(archivo):\n",
        "                !git add {archivo}\n",
        "                archivos_a√±adidos += 1\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Advertencia: No se encontr√≥ el archivo {archivo}\")\n",
        "\n",
        "        if archivos_a√±adidos == 0:\n",
        "            print(\"‚ùå No se encontraron archivos v√°lidos para subir.\")\n",
        "            return\n",
        "\n",
        "        # 2. Commit con marca de tiempo autom√°tica si no se provee mensaje detallado\n",
        "        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
        "        full_message = f\"{mensaje_commit} ({timestamp})\"\n",
        "\n",
        "        # El comando commit devuelve error si no hay cambios, usamos try interno\n",
        "        !git commit -m \"{full_message}\"\n",
        "\n",
        "        # 3. Pull y Push\n",
        "        print(f\"üöÄ Enviando {archivos_a√±adidos} archivo(s) a GitHub...\")\n",
        "        !git pull --rebase -X ours origin main\n",
        "        !git push origin main\n",
        "        print(f\"‚úÖ Sincronizaci√≥n exitosa.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error durante la sincronizaci√≥n: {e}\")\n",
        "    finally:\n",
        "        %cd /content/\n"
      ],
      "metadata": {
        "id": "7e2s7yqa_4kc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 5. EXTRACCI√ìN Y SUBIDA DE DATASET\n",
        "# ==========================================\n",
        "\n",
        "REPO_NAME_EXTRACCION = 'OCA/l10n-spain'\n",
        "LIMITE_REGISTROS = 200\n",
        "datos_github_csv = 'datos_github.csv'\n",
        "ruta_datos_github_csv = os.path.join(ruta_local_data, datos_github_csv)\n",
        "\n",
        "if os.path.exists(ruta_datos_github_csv):\n",
        "    print(f\"‚úÖ El archivo '{datos_github_csv}' ya existe en el repositorio local.\")\n",
        "    print(\"üöÄ Se saltar√° la descarga para ahorrar recursos y tiempo.\")\n",
        "else:\n",
        "    try:\n",
        "        auth = Auth.Token(TOKEN)\n",
        "        g = Github(auth=auth)\n",
        "        repo = g.get_repo(REPO_NAME_EXTRACCION)\n",
        "        dataset = []\n",
        "\n",
        "        # --- EXTRACCI√ìN DE ISSUES (RF-01) ---\n",
        "\n",
        "        print(f\"\\n--- Extrayendo hasta {LIMITE_REGISTROS} Issues ---\")\n",
        "        issues = repo.get_issues(state='all', sort='created', direction='desc')\n",
        "        count = 0\n",
        "\n",
        "        for item in issues:\n",
        "            if count >= LIMITE_REGISTROS: break\n",
        "            if item.pull_request is not None: continue\n",
        "\n",
        "            print(f\"üì• Procesando Issue #{item.number}...\")\n",
        "\n",
        "            # Recolectar t√≠tulo, descripci√≥n y comentarios\n",
        "            titulo = item.title or \"\"\n",
        "            descripcion = item.body or \"\"\n",
        "            comments = [c.body for c in item.get_comments() if c.body]\n",
        "\n",
        "            # L√≥gica modificada: Una fila por cada comentario\n",
        "            if comments:\n",
        "                for comm in comments:\n",
        "                    dataset.append({\n",
        "                        'tipo': 'Issue',\n",
        "                        'numero': item.number,\n",
        "                        'titulo': titulo,\n",
        "                        'descripcion': descripcion,\n",
        "                        'comentarios': comm  # Comentario individual\n",
        "                    })\n",
        "            else:\n",
        "                # Si no hay comentarios, guardamos el Issue de todas formas\n",
        "                dataset.append({\n",
        "                    'tipo': 'Issue',\n",
        "                    'numero': item.number,\n",
        "                    'titulo': titulo,\n",
        "                    'descripcion': descripcion,\n",
        "                    'comentarios': \"\"\n",
        "                })\n",
        "\n",
        "            count += 1\n",
        "\n",
        "        # --- EXTRACCI√ìN DE PULL REQUESTS (RF-01) ---\n",
        "        print(f\"\\n--- Extrayendo hasta {LIMITE_REGISTROS} Pull Requests ---\")\n",
        "        pulls = repo.get_pulls(state='all', sort='created', direction='desc')\n",
        "        count = 0\n",
        "\n",
        "        for pr in pulls:\n",
        "            if count >= LIMITE_REGISTROS: break\n",
        "\n",
        "            print(f\"üì• Procesando PR #{pr.number}...\")\n",
        "\n",
        "            # Recolectar t√≠tulo, descripci√≥n y comentarios asociados\n",
        "            titulo = pr.title or \"\"\n",
        "            descripcion = pr.body or \"\"\n",
        "            comments = [c.body for c in pr.get_issue_comments() if c.body]\n",
        "\n",
        "            # L√≥gica modificada: Una fila por cada comentario\n",
        "            if comments:\n",
        "                for comm in comments:\n",
        "                    dataset.append({\n",
        "                        'tipo': 'Pull Request',\n",
        "                        'numero': pr.number,\n",
        "                        'titulo': titulo,\n",
        "                        'descripcion': descripcion,\n",
        "                        'comentarios': comm  # Comentario individual\n",
        "                    })\n",
        "            else:\n",
        "                # Si no hay comentarios, guardamos el PR de todas formas\n",
        "                dataset.append({\n",
        "                    'tipo': 'Pull Request',\n",
        "                    'numero': pr.number,\n",
        "                    'titulo': titulo,\n",
        "                    'descripcion': descripcion,\n",
        "                    'comentarios': \"\"\n",
        "                })\n",
        "\n",
        "            count += 1\n",
        "\n",
        "        # --- SECCI√ìN DE GUARDADO INTEGRADA ---\n",
        "        if dataset:\n",
        "            df = pd.DataFrame(dataset)\n",
        "\n",
        "            #Guardar localmente en la carpeta data del repo\n",
        "            df.to_csv(ruta_datos_github_csv, index=False, encoding='utf-8-sig')\n",
        "            print(f\"üìÑ Archivo generado en: {ruta_datos_github_csv}\")\n",
        "            #Sincronizaci√≥n con GitHub (Commit y Push)\n",
        "            sincronizar_con_github(ruta_local_data, [datos_github_csv], \"Actualizaci√≥n autom√°tica de extracci√≥n inicial\")\n",
        "            print(\"‚úÖ Proceso de extracci√≥n, guardado y push finalizado.\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è No se generaron datos para subir.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error en Celda de Extracci√≥n: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3T296idgcR0",
        "outputId": "8aaa3dc1-a391-40f0-ca13-bf8ba671e492"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Extrayendo hasta 200 Issues ---\n",
            "üì• Procesando Issue #4810...\n",
            "üì• Procesando Issue #4793...\n",
            "üì• Procesando Issue #4760...\n",
            "üì• Procesando Issue #4743...\n",
            "üì• Procesando Issue #4681...\n",
            "üì• Procesando Issue #4677...\n",
            "üì• Procesando Issue #4666...\n",
            "üì• Procesando Issue #4652...\n",
            "üì• Procesando Issue #4650...\n",
            "üì• Procesando Issue #4649...\n",
            "üì• Procesando Issue #4642...\n",
            "üì• Procesando Issue #4641...\n",
            "üì• Procesando Issue #4639...\n",
            "üì• Procesando Issue #4637...\n",
            "üì• Procesando Issue #4632...\n",
            "üì• Procesando Issue #4631...\n",
            "üì• Procesando Issue #4626...\n",
            "üì• Procesando Issue #4623...\n",
            "üì• Procesando Issue #4620...\n",
            "üì• Procesando Issue #4618...\n",
            "üì• Procesando Issue #4615...\n",
            "üì• Procesando Issue #4613...\n",
            "üì• Procesando Issue #4605...\n",
            "üì• Procesando Issue #4604...\n",
            "üì• Procesando Issue #4603...\n",
            "üì• Procesando Issue #4596...\n",
            "üì• Procesando Issue #4591...\n",
            "üì• Procesando Issue #4589...\n",
            "üì• Procesando Issue #4586...\n",
            "üì• Procesando Issue #4550...\n",
            "üì• Procesando Issue #4534...\n",
            "üì• Procesando Issue #4507...\n",
            "üì• Procesando Issue #4497...\n",
            "üì• Procesando Issue #4489...\n",
            "üì• Procesando Issue #4472...\n",
            "üì• Procesando Issue #4468...\n",
            "üì• Procesando Issue #4467...\n",
            "üì• Procesando Issue #4463...\n",
            "üì• Procesando Issue #4462...\n",
            "üì• Procesando Issue #4457...\n",
            "üì• Procesando Issue #4444...\n",
            "üì• Procesando Issue #4435...\n",
            "üì• Procesando Issue #4430...\n",
            "üì• Procesando Issue #4428...\n",
            "üì• Procesando Issue #4425...\n",
            "üì• Procesando Issue #4424...\n",
            "üì• Procesando Issue #4423...\n",
            "üì• Procesando Issue #4421...\n",
            "üì• Procesando Issue #4420...\n",
            "üì• Procesando Issue #4419...\n",
            "üì• Procesando Issue #4416...\n",
            "üì• Procesando Issue #4402...\n",
            "üì• Procesando Issue #4397...\n",
            "üì• Procesando Issue #4391...\n",
            "üì• Procesando Issue #4390...\n",
            "üì• Procesando Issue #4389...\n",
            "üì• Procesando Issue #4387...\n",
            "üì• Procesando Issue #4385...\n",
            "üì• Procesando Issue #4381...\n",
            "üì• Procesando Issue #4376...\n",
            "üì• Procesando Issue #4375...\n",
            "üì• Procesando Issue #4374...\n",
            "üì• Procesando Issue #4372...\n",
            "üì• Procesando Issue #4368...\n",
            "üì• Procesando Issue #4366...\n",
            "üì• Procesando Issue #4358...\n",
            "üì• Procesando Issue #4341...\n",
            "üì• Procesando Issue #4338...\n",
            "üì• Procesando Issue #4302...\n",
            "üì• Procesando Issue #4291...\n",
            "üì• Procesando Issue #4289...\n",
            "üì• Procesando Issue #4286...\n",
            "üì• Procesando Issue #4272...\n",
            "üì• Procesando Issue #4271...\n",
            "üì• Procesando Issue #4262...\n",
            "üì• Procesando Issue #4237...\n",
            "üì• Procesando Issue #4223...\n",
            "üì• Procesando Issue #4213...\n",
            "üì• Procesando Issue #4211...\n",
            "üì• Procesando Issue #4207...\n",
            "üì• Procesando Issue #4206...\n",
            "üì• Procesando Issue #4198...\n",
            "üì• Procesando Issue #4197...\n",
            "üì• Procesando Issue #4196...\n",
            "üì• Procesando Issue #4185...\n",
            "üì• Procesando Issue #4178...\n",
            "üì• Procesando Issue #4173...\n",
            "üì• Procesando Issue #4169...\n",
            "üì• Procesando Issue #4165...\n",
            "üì• Procesando Issue #4155...\n",
            "üì• Procesando Issue #4140...\n",
            "üì• Procesando Issue #4138...\n",
            "üì• Procesando Issue #4115...\n",
            "üì• Procesando Issue #4110...\n",
            "üì• Procesando Issue #4103...\n",
            "üì• Procesando Issue #4102...\n",
            "üì• Procesando Issue #4100...\n",
            "üì• Procesando Issue #4094...\n",
            "üì• Procesando Issue #4092...\n",
            "üì• Procesando Issue #4085...\n",
            "üì• Procesando Issue #4077...\n",
            "üì• Procesando Issue #4060...\n",
            "üì• Procesando Issue #4051...\n",
            "üì• Procesando Issue #4042...\n",
            "üì• Procesando Issue #4039...\n",
            "üì• Procesando Issue #4024...\n",
            "üì• Procesando Issue #4020...\n",
            "üì• Procesando Issue #4017...\n",
            "üì• Procesando Issue #4016...\n",
            "üì• Procesando Issue #4008...\n",
            "üì• Procesando Issue #3999...\n",
            "üì• Procesando Issue #3995...\n",
            "üì• Procesando Issue #3984...\n",
            "üì• Procesando Issue #3971...\n",
            "üì• Procesando Issue #3970...\n",
            "üì• Procesando Issue #3961...\n",
            "üì• Procesando Issue #3942...\n",
            "üì• Procesando Issue #3941...\n",
            "üì• Procesando Issue #3900...\n",
            "üì• Procesando Issue #3896...\n",
            "üì• Procesando Issue #3886...\n",
            "üì• Procesando Issue #3881...\n",
            "üì• Procesando Issue #3876...\n",
            "üì• Procesando Issue #3872...\n",
            "üì• Procesando Issue #3868...\n",
            "üì• Procesando Issue #3864...\n",
            "üì• Procesando Issue #3862...\n",
            "üì• Procesando Issue #3861...\n",
            "üì• Procesando Issue #3858...\n",
            "üì• Procesando Issue #3856...\n",
            "üì• Procesando Issue #3851...\n",
            "üì• Procesando Issue #3842...\n",
            "üì• Procesando Issue #3831...\n",
            "üì• Procesando Issue #3829...\n",
            "üì• Procesando Issue #3826...\n",
            "üì• Procesando Issue #3823...\n",
            "üì• Procesando Issue #3812...\n",
            "üì• Procesando Issue #3806...\n",
            "üì• Procesando Issue #3799...\n",
            "üì• Procesando Issue #3790...\n",
            "üì• Procesando Issue #3787...\n",
            "üì• Procesando Issue #3786...\n",
            "üì• Procesando Issue #3754...\n",
            "üì• Procesando Issue #3751...\n",
            "üì• Procesando Issue #3730...\n",
            "üì• Procesando Issue #3721...\n",
            "üì• Procesando Issue #3720...\n",
            "üì• Procesando Issue #3718...\n",
            "üì• Procesando Issue #3703...\n",
            "üì• Procesando Issue #3700...\n",
            "üì• Procesando Issue #3699...\n",
            "üì• Procesando Issue #3698...\n",
            "üì• Procesando Issue #3690...\n",
            "üì• Procesando Issue #3689...\n",
            "üì• Procesando Issue #3688...\n",
            "üì• Procesando Issue #3682...\n",
            "üì• Procesando Issue #3680...\n",
            "üì• Procesando Issue #3676...\n",
            "üì• Procesando Issue #3670...\n",
            "üì• Procesando Issue #3669...\n",
            "üì• Procesando Issue #3668...\n",
            "üì• Procesando Issue #3660...\n",
            "üì• Procesando Issue #3650...\n",
            "üì• Procesando Issue #3647...\n",
            "üì• Procesando Issue #3641...\n",
            "üì• Procesando Issue #3636...\n",
            "üì• Procesando Issue #3627...\n",
            "üì• Procesando Issue #3624...\n",
            "üì• Procesando Issue #3622...\n",
            "üì• Procesando Issue #3610...\n",
            "üì• Procesando Issue #3607...\n",
            "üì• Procesando Issue #3605...\n",
            "üì• Procesando Issue #3589...\n",
            "üì• Procesando Issue #3565...\n",
            "üì• Procesando Issue #3560...\n",
            "üì• Procesando Issue #3552...\n",
            "üì• Procesando Issue #3551...\n",
            "üì• Procesando Issue #3539...\n",
            "üì• Procesando Issue #3538...\n",
            "üì• Procesando Issue #3533...\n",
            "üì• Procesando Issue #3527...\n",
            "üì• Procesando Issue #3522...\n",
            "üì• Procesando Issue #3521...\n",
            "üì• Procesando Issue #3520...\n",
            "üì• Procesando Issue #3518...\n",
            "üì• Procesando Issue #3514...\n",
            "üì• Procesando Issue #3507...\n",
            "üì• Procesando Issue #3500...\n",
            "üì• Procesando Issue #3483...\n",
            "üì• Procesando Issue #3482...\n",
            "üì• Procesando Issue #3480...\n",
            "üì• Procesando Issue #3475...\n",
            "üì• Procesando Issue #3474...\n",
            "üì• Procesando Issue #3459...\n",
            "üì• Procesando Issue #3456...\n",
            "üì• Procesando Issue #3455...\n",
            "üì• Procesando Issue #3452...\n",
            "üì• Procesando Issue #3451...\n",
            "üì• Procesando Issue #3450...\n",
            "üì• Procesando Issue #3449...\n",
            "\n",
            "--- Extrayendo hasta 200 Pull Requests ---\n",
            "üì• Procesando PR #4811...\n",
            "üì• Procesando PR #4809...\n",
            "üì• Procesando PR #4808...\n",
            "üì• Procesando PR #4807...\n",
            "üì• Procesando PR #4806...\n",
            "üì• Procesando PR #4805...\n",
            "üì• Procesando PR #4804...\n",
            "üì• Procesando PR #4803...\n",
            "üì• Procesando PR #4802...\n",
            "üì• Procesando PR #4801...\n",
            "üì• Procesando PR #4800...\n",
            "üì• Procesando PR #4799...\n",
            "üì• Procesando PR #4798...\n",
            "üì• Procesando PR #4797...\n",
            "üì• Procesando PR #4796...\n",
            "üì• Procesando PR #4795...\n",
            "üì• Procesando PR #4794...\n",
            "üì• Procesando PR #4792...\n",
            "üì• Procesando PR #4791...\n",
            "üì• Procesando PR #4790...\n",
            "üì• Procesando PR #4789...\n",
            "üì• Procesando PR #4788...\n",
            "üì• Procesando PR #4787...\n",
            "üì• Procesando PR #4786...\n",
            "üì• Procesando PR #4785...\n",
            "üì• Procesando PR #4784...\n",
            "üì• Procesando PR #4783...\n",
            "üì• Procesando PR #4782...\n",
            "üì• Procesando PR #4781...\n",
            "üì• Procesando PR #4780...\n",
            "üì• Procesando PR #4779...\n",
            "üì• Procesando PR #4778...\n",
            "üì• Procesando PR #4777...\n",
            "üì• Procesando PR #4776...\n",
            "üì• Procesando PR #4775...\n",
            "üì• Procesando PR #4774...\n",
            "üì• Procesando PR #4773...\n",
            "üì• Procesando PR #4772...\n",
            "üì• Procesando PR #4771...\n",
            "üì• Procesando PR #4770...\n",
            "üì• Procesando PR #4769...\n",
            "üì• Procesando PR #4768...\n",
            "üì• Procesando PR #4767...\n",
            "üì• Procesando PR #4766...\n",
            "üì• Procesando PR #4765...\n",
            "üì• Procesando PR #4764...\n",
            "üì• Procesando PR #4763...\n",
            "üì• Procesando PR #4762...\n",
            "üì• Procesando PR #4761...\n",
            "üì• Procesando PR #4759...\n",
            "üì• Procesando PR #4758...\n",
            "üì• Procesando PR #4757...\n",
            "üì• Procesando PR #4756...\n",
            "üì• Procesando PR #4755...\n",
            "üì• Procesando PR #4754...\n",
            "üì• Procesando PR #4753...\n",
            "üì• Procesando PR #4752...\n",
            "üì• Procesando PR #4751...\n",
            "üì• Procesando PR #4750...\n",
            "üì• Procesando PR #4749...\n",
            "üì• Procesando PR #4748...\n",
            "üì• Procesando PR #4747...\n",
            "üì• Procesando PR #4746...\n",
            "üì• Procesando PR #4745...\n",
            "üì• Procesando PR #4744...\n",
            "üì• Procesando PR #4742...\n",
            "üì• Procesando PR #4741...\n",
            "üì• Procesando PR #4740...\n",
            "üì• Procesando PR #4739...\n",
            "üì• Procesando PR #4738...\n",
            "üì• Procesando PR #4737...\n",
            "üì• Procesando PR #4736...\n",
            "üì• Procesando PR #4735...\n",
            "üì• Procesando PR #4734...\n",
            "üì• Procesando PR #4733...\n",
            "üì• Procesando PR #4732...\n",
            "üì• Procesando PR #4731...\n",
            "üì• Procesando PR #4730...\n",
            "üì• Procesando PR #4729...\n",
            "üì• Procesando PR #4728...\n",
            "üì• Procesando PR #4727...\n",
            "üì• Procesando PR #4726...\n",
            "üì• Procesando PR #4725...\n",
            "üì• Procesando PR #4724...\n",
            "üì• Procesando PR #4723...\n",
            "üì• Procesando PR #4722...\n",
            "üì• Procesando PR #4721...\n",
            "üì• Procesando PR #4720...\n",
            "üì• Procesando PR #4719...\n",
            "üì• Procesando PR #4718...\n",
            "üì• Procesando PR #4717...\n",
            "üì• Procesando PR #4716...\n",
            "üì• Procesando PR #4715...\n",
            "üì• Procesando PR #4714...\n",
            "üì• Procesando PR #4713...\n",
            "üì• Procesando PR #4712...\n",
            "üì• Procesando PR #4711...\n",
            "üì• Procesando PR #4710...\n",
            "üì• Procesando PR #4709...\n",
            "üì• Procesando PR #4708...\n",
            "üì• Procesando PR #4707...\n",
            "üì• Procesando PR #4706...\n",
            "üì• Procesando PR #4705...\n",
            "üì• Procesando PR #4704...\n",
            "üì• Procesando PR #4703...\n",
            "üì• Procesando PR #4702...\n",
            "üì• Procesando PR #4701...\n",
            "üì• Procesando PR #4700...\n",
            "üì• Procesando PR #4699...\n",
            "üì• Procesando PR #4698...\n",
            "üì• Procesando PR #4697...\n",
            "üì• Procesando PR #4696...\n",
            "üì• Procesando PR #4695...\n",
            "üì• Procesando PR #4694...\n",
            "üì• Procesando PR #4693...\n",
            "üì• Procesando PR #4692...\n",
            "üì• Procesando PR #4691...\n",
            "üì• Procesando PR #4690...\n",
            "üì• Procesando PR #4689...\n",
            "üì• Procesando PR #4688...\n",
            "üì• Procesando PR #4687...\n",
            "üì• Procesando PR #4686...\n",
            "üì• Procesando PR #4685...\n",
            "üì• Procesando PR #4684...\n",
            "üì• Procesando PR #4683...\n",
            "üì• Procesando PR #4682...\n",
            "üì• Procesando PR #4680...\n",
            "üì• Procesando PR #4679...\n",
            "üì• Procesando PR #4676...\n",
            "üì• Procesando PR #4675...\n",
            "üì• Procesando PR #4674...\n",
            "üì• Procesando PR #4673...\n",
            "üì• Procesando PR #4672...\n",
            "üì• Procesando PR #4671...\n",
            "üì• Procesando PR #4670...\n",
            "üì• Procesando PR #4669...\n",
            "üì• Procesando PR #4668...\n",
            "üì• Procesando PR #4667...\n",
            "üì• Procesando PR #4665...\n",
            "üì• Procesando PR #4664...\n",
            "üì• Procesando PR #4663...\n",
            "üì• Procesando PR #4662...\n",
            "üì• Procesando PR #4661...\n",
            "üì• Procesando PR #4660...\n",
            "üì• Procesando PR #4659...\n",
            "üì• Procesando PR #4658...\n",
            "üì• Procesando PR #4656...\n",
            "üì• Procesando PR #4655...\n",
            "üì• Procesando PR #4654...\n",
            "üì• Procesando PR #4653...\n",
            "üì• Procesando PR #4651...\n",
            "üì• Procesando PR #4648...\n",
            "üì• Procesando PR #4647...\n",
            "üì• Procesando PR #4646...\n",
            "üì• Procesando PR #4645...\n",
            "üì• Procesando PR #4644...\n",
            "üì• Procesando PR #4640...\n",
            "üì• Procesando PR #4638...\n",
            "üì• Procesando PR #4636...\n",
            "üì• Procesando PR #4635...\n",
            "üì• Procesando PR #4634...\n",
            "üì• Procesando PR #4633...\n",
            "üì• Procesando PR #4630...\n",
            "üì• Procesando PR #4629...\n",
            "üì• Procesando PR #4627...\n",
            "üì• Procesando PR #4625...\n",
            "üì• Procesando PR #4624...\n",
            "üì• Procesando PR #4622...\n",
            "üì• Procesando PR #4619...\n",
            "üì• Procesando PR #4617...\n",
            "üì• Procesando PR #4616...\n",
            "üì• Procesando PR #4614...\n",
            "üì• Procesando PR #4612...\n",
            "üì• Procesando PR #4611...\n",
            "üì• Procesando PR #4610...\n",
            "üì• Procesando PR #4609...\n",
            "üì• Procesando PR #4608...\n",
            "üì• Procesando PR #4607...\n",
            "üì• Procesando PR #4606...\n",
            "üì• Procesando PR #4602...\n",
            "üì• Procesando PR #4601...\n",
            "üì• Procesando PR #4600...\n",
            "üì• Procesando PR #4599...\n",
            "üì• Procesando PR #4598...\n",
            "üì• Procesando PR #4595...\n",
            "üì• Procesando PR #4594...\n",
            "üì• Procesando PR #4593...\n",
            "üì• Procesando PR #4592...\n",
            "üì• Procesando PR #4590...\n",
            "üì• Procesando PR #4588...\n",
            "üì• Procesando PR #4587...\n",
            "üì• Procesando PR #4585...\n",
            "üì• Procesando PR #4584...\n",
            "üì• Procesando PR #4583...\n",
            "üì• Procesando PR #4582...\n",
            "üì• Procesando PR #4581...\n",
            "üì• Procesando PR #4580...\n",
            "üì• Procesando PR #4579...\n",
            "üì• Procesando PR #4577...\n",
            "üì• Procesando PR #4576...\n",
            "üìÑ Archivo generado en: /content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data/datos_github.csv\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main e957614] Actualizaci√≥n autom√°tica de extracci√≥n inicial (2026-02-10 19:54)\n",
            " 1 file changed, 149 insertions(+), 125 deletions(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "error: cannot pull with rebase: You have unstaged changes.\n",
            "error: please commit or stash them.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 3.78 KiB | 154.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   6a5295b..e957614  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Proceso de extracci√≥n, guardado y push finalizado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================================\n",
        "# 6. CARGA Y REVISI√ìN DE DATOS\n",
        "# ==========================================\n",
        "\n",
        "file_path = '/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data/datos_github.csv'\n",
        "\n",
        "data = pd.read_csv(file_path)\n",
        "print(data.count())\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "uLgbpweddIYn",
        "outputId": "8be1aa13-aa97-4f92-e056-9572bbfaf4f7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tipo           1495\n",
            "numero         1495\n",
            "titulo         1495\n",
            "descripcion    1455\n",
            "comentarios    1451\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              tipo  numero                                             titulo  \\\n",
              "0            Issue    4810  [15.0] [l10n_es_verifactu_oca] Bucle de reinte...   \n",
              "1            Issue    4793  MOD347 : Error E010330 Caracteres no v√°lidos '...   \n",
              "2            Issue    4760                 Actualizar modelo 190 en rama 16.0   \n",
              "3            Issue    4760                 Actualizar modelo 190 en rama 16.0   \n",
              "4            Issue    4760                 Actualizar modelo 190 en rama 16.0   \n",
              "...            ...     ...                                                ...   \n",
              "1490  Pull Request    4576  [18.0][FIX] l10n_es_aeat: Find properly the XM...   \n",
              "1491  Pull Request    4576  [18.0][FIX] l10n_es_aeat: Find properly the XM...   \n",
              "1492  Pull Request    4576  [18.0][FIX] l10n_es_aeat: Find properly the XM...   \n",
              "1493  Pull Request    4576  [18.0][FIX] l10n_es_aeat: Find properly the XM...   \n",
              "1494  Pull Request    4576  [18.0][FIX] l10n_es_aeat: Find properly the XM...   \n",
              "\n",
              "                                            descripcion  \\\n",
              "0     <!-- Provide a general summary of the issue in...   \n",
              "1     module: l10n_es_aeat_mod347\\nversion: 18.0\\n\\n...   \n",
              "2     Actualmente, al generar el fichero del modelo ...   \n",
              "3     Actualmente, al generar el fichero del modelo ...   \n",
              "4     Actualmente, al generar el fichero del modelo ...   \n",
              "...                                                 ...   \n",
              "1490  Forward-port of #4573 \\r\\n\\r\\nThe tax groups a...   \n",
              "1491  Forward-port of #4573 \\r\\n\\r\\nThe tax groups a...   \n",
              "1492  Forward-port of #4573 \\r\\n\\r\\nThe tax groups a...   \n",
              "1493  Forward-port of #4573 \\r\\n\\r\\nThe tax groups a...   \n",
              "1494  Forward-port of #4573 \\r\\n\\r\\nThe tax groups a...   \n",
              "\n",
              "                                            comentarios  \n",
              "0                                                   NaN  \n",
              "1                              Siendo tratado en #4784   \n",
              "2     Adem√°s, hemos podido comprobar que el mismo pr...  \n",
              "3     S√≠, desde luego la soluci√≥n pasa por llevar es...  \n",
              "4     @pedrobaeza Gracias por la aclaraci√≥n.\\nDe acu...  \n",
              "...                                                 ...  \n",
              "1490  On my way to merge this fine PR!\\nPrepared bra...  \n",
              "1491  @pedrobaeza your merge command was aborted due...  \n",
              "1492                                /ocabot merge patch  \n",
              "1493  On my way to merge this fine PR!\\nPrepared bra...  \n",
              "1494  Congratulations, your PR was merged at 9f6c6d1...  \n",
              "\n",
              "[1495 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5d23f6c-88c8-4618-8106-6938192451ac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tipo</th>\n",
              "      <th>numero</th>\n",
              "      <th>titulo</th>\n",
              "      <th>descripcion</th>\n",
              "      <th>comentarios</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Issue</td>\n",
              "      <td>4810</td>\n",
              "      <td>[15.0] [l10n_es_verifactu_oca] Bucle de reinte...</td>\n",
              "      <td>&lt;!-- Provide a general summary of the issue in...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Issue</td>\n",
              "      <td>4793</td>\n",
              "      <td>MOD347 : Error E010330 Caracteres no v√°lidos '...</td>\n",
              "      <td>module: l10n_es_aeat_mod347\\nversion: 18.0\\n\\n...</td>\n",
              "      <td>Siendo tratado en #4784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Issue</td>\n",
              "      <td>4760</td>\n",
              "      <td>Actualizar modelo 190 en rama 16.0</td>\n",
              "      <td>Actualmente, al generar el fichero del modelo ...</td>\n",
              "      <td>Adem√°s, hemos podido comprobar que el mismo pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Issue</td>\n",
              "      <td>4760</td>\n",
              "      <td>Actualizar modelo 190 en rama 16.0</td>\n",
              "      <td>Actualmente, al generar el fichero del modelo ...</td>\n",
              "      <td>S√≠, desde luego la soluci√≥n pasa por llevar es...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Issue</td>\n",
              "      <td>4760</td>\n",
              "      <td>Actualizar modelo 190 en rama 16.0</td>\n",
              "      <td>Actualmente, al generar el fichero del modelo ...</td>\n",
              "      <td>@pedrobaeza Gracias por la aclaraci√≥n.\\nDe acu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1490</th>\n",
              "      <td>Pull Request</td>\n",
              "      <td>4576</td>\n",
              "      <td>[18.0][FIX] l10n_es_aeat: Find properly the XM...</td>\n",
              "      <td>Forward-port of #4573 \\r\\n\\r\\nThe tax groups a...</td>\n",
              "      <td>On my way to merge this fine PR!\\nPrepared bra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1491</th>\n",
              "      <td>Pull Request</td>\n",
              "      <td>4576</td>\n",
              "      <td>[18.0][FIX] l10n_es_aeat: Find properly the XM...</td>\n",
              "      <td>Forward-port of #4573 \\r\\n\\r\\nThe tax groups a...</td>\n",
              "      <td>@pedrobaeza your merge command was aborted due...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1492</th>\n",
              "      <td>Pull Request</td>\n",
              "      <td>4576</td>\n",
              "      <td>[18.0][FIX] l10n_es_aeat: Find properly the XM...</td>\n",
              "      <td>Forward-port of #4573 \\r\\n\\r\\nThe tax groups a...</td>\n",
              "      <td>/ocabot merge patch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1493</th>\n",
              "      <td>Pull Request</td>\n",
              "      <td>4576</td>\n",
              "      <td>[18.0][FIX] l10n_es_aeat: Find properly the XM...</td>\n",
              "      <td>Forward-port of #4573 \\r\\n\\r\\nThe tax groups a...</td>\n",
              "      <td>On my way to merge this fine PR!\\nPrepared bra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494</th>\n",
              "      <td>Pull Request</td>\n",
              "      <td>4576</td>\n",
              "      <td>[18.0][FIX] l10n_es_aeat: Find properly the XM...</td>\n",
              "      <td>Forward-port of #4573 \\r\\n\\r\\nThe tax groups a...</td>\n",
              "      <td>Congratulations, your PR was merged at 9f6c6d1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1495 rows √ó 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5d23f6c-88c8-4618-8106-6938192451ac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f5d23f6c-88c8-4618-8106-6938192451ac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f5d23f6c-88c8-4618-8106-6938192451ac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_9ae132bf-6933-4ff2-a759-9e81f094426c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9ae132bf-6933-4ff2-a759-9e81f094426c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1495,\n  \"fields\": [\n    {\n      \"column\": \"tipo\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Pull Request\",\n          \"Issue\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"numero\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 424,\n        \"min\": 3449,\n        \"max\": 4811,\n        \"num_unique_values\": 400,\n        \"samples\": [\n          4801,\n          4727\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"titulo\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 399,\n        \"samples\": [\n          \"Persona f\\u00edsica - l10n_es_facturae - Odoo 14\",\n          \"[17.0][IMP] l10n_es_account_statement_import_n43: Add exclude pattern\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"descripcion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 383,\n        \"samples\": [\n          \"Antes de este fix, a la hora de a\\u00f1adir un socio destinatario durante la creaci\\u00f3n del reporte, saltaba un error que lo hac\\u00eda imposible.\\r\\n\\r\\nhttps://www.loom.com/share/1f1df1b6ed78452cb1c06c71594690c7\\r\\n\\r\\nMT-13290 @moduon\",\n          \"TT59873\\r\\n\\r\\n@Tecnativa @pedrobaeza @sergio-teruel @christian-ramos-tecnativa could you please review this?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comentarios\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1261,\n        \"samples\": [\n          \"> Buenas [@Joaco1980](https://github.com/Joaco1980) No entiendo muy bien como reproducir el error que comentas. Yo he realizado dos ventas en el POS sin seleccionar cliente y no me da ning\\u00fan error. Las ventas \\\"facturas simplificadas\\\" se env\\u00edan correctamente a TBAI.\\n\\nVale para replicarlo, crear un cliente nuevo \\\"PEPITO FLORES\\\" y d\\u00e9jale sin CP introducido, mete si quieres provincia, pa\\u00eds y todos los datos que consideres pero deja vac\\u00edo el CP. \\n\\nEs ahi donde da el error que comento, ademas si recargas la pagina y vuelves a crear el ticket se crea correctamente pero falla la transmisi\\u00f3n y da error cuando haces un ticket despu\\u00e9s de este error:\\n\\nES): El XML del fichero TicketBAI no cumple el esquema.[Linea:2 Columna:1706] Error:cvc-pattern-valid: Value 'aN-aN-NaN' is not facet-valid with respect to pattern '\\\\d{2,2}-\\\\d{2,2}-\\\\d{4,4}' for type 'FechaType'.(EU): TicketBAI fitxategiaren XMLak ez du eskema betetzen.[Linea:2 Columna:1706] Error:cvc-pattern-valid: Value 'aN-aN-NaN' is not facet-valid with respect to pattern '\\\\d{2,2}-\\\\d{2,2}-\\\\d{4,4}' for type 'FechaType'.\\n\\nConcretamente da un error de validaci\\u00f3n con la fecha de la factura anterior que la deja asi en el xml:\\n<FechaExpedicionFacturaAnterior>aN-aN-NaN</FechaExpedicionFacturaAnterior>\\n\\nYo estoy subiendo los tickets con error en la subida manualmente en el LROE poniendo esa fecha bien no se si es la manera correcta de hacerlo pero al menos se validan, porque el bot\\u00f3n de Cancelar y recrear no sirve en este caso concreto.\",\n          \"Seg\\u00fan el dise\\u00f1o de registro del Libro de IVA que se puede encontrar [aqu\\u00ed](https://sede.agenciatributaria.gob.es/Sede/iva/libros-registro.html) y descargar desde este enlace [Dise\\u00f1os de registro normalizados para los Libros Registro del IVA de personas jur\\u00eddicas no incluidas en SII en los formatos XLS y CSV (actualizado 18-12-2024)](https://sede.agenciatributaria.gob.es/static_files/AEAT/LSIJ.xlsx):\\n\\n> - En \\\"Cuota Deducible\\\" se consignar\\u00e1 el importe de la Cuota del IVA Soportado que sea deducible para cada tipo de IVA. Cuando toda la cuota soportada sea deducible, en la columna \\\"Cuota Deducible\\\" se consignar\\u00e1 el mismo contenido que figure en la columna \\\"Cuota IVA Soportado\\\". \\n\\nEs decir, que seg\\u00fan el ejemplo de @rafaelbn con una prorrata del 80% configurada en la compa\\u00f1\\u00eda entonces el valor mostrado en \\\"Cuota IVA Siportado\\\" deber\\u00eda ser diferente al valor mostrado en \\\"Cuota deducible\\\", concretamente un 80% en este caso. S\\u00f3lo deber\\u00edan coincidir cuando toda la cuota soportada sea deducible.\\n\\nActualmente con los dos m\\u00f3dulos instalados `l10n_es_vat_book` y `l10n_es_vat_prorate` el valor mostrado es id\\u00e9ntico en \\\"Cuota IVA Soportado\\\" y \\\"Cuota deducible\\\" dando a entender que toda la cuota soportada es deducible independientemente del valor que te hayas deducido. Tambi\\u00e9n se est\\u00e1 viendo afectado \\\"Total de factura\\\" pues el valor reflejado es la Base Imponible + Cuota Deducible, pareciendo que el IVA est\\u00e1 m\\u00e1l aplicado.\\n\\nEjemplo pr\\u00e1ctico de una factura de una compa\\u00f1ia con la Prorrata del IVA al 80% para este per\\u00edodo y con dos l\\u00edneas de factura, una l\\u00ednea con un importe de 100 \\u20ac y un impuesto del 21% y otra l\\u00ednea de 200\\u20ac con el mismo impuesto.\\n\\n![Image](https://github.com/user-attachments/assets/097d527b-11ad-48d2-b0a6-792d316bccbc)\\n\\n- El total de la factura son 363\\u20ac.\\n- La cuota de IVA Soportado es 63\\u20ac, el 21% de 100\\u20ac m\\u00e1s el 21% de 200\\u20ac.\\n- La cuota deducible es 50,40\\u20ac, el 80% de la cuota de IVA soportado.\\n\\n\\nSin enmbargo el libro de IVA est\\u00e1 haciendo un c\\u00e1lculo incorrecto, con este ejemplo sale:\\n\\n![Image](https://github.com/user-attachments/assets/bc39ab8f-904d-4010-a7e2-197267f3dc69)\\n\\nA todas luces se ve que el c\\u00e1lculo es incorrecto.\\n\\n\\u00bfCu\\u00e1l cree\\u00eds que es la soluci\\u00f3n correcta @pedrobaeza @HaraldPanten @etobella? \\u00bfCrear un m\\u00f3dulo glue, por ejemplo, `l10n_es_vat_book_prorate` o solventarlo directamente en `l10n_es_vat_book`?\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 7. PREPROCESADO DE DATOS\n",
        "# ==========================================\n",
        "\n",
        "pln_datos_github_csv = 'pln_datos_github.csv'\n",
        "ruta_pln_datos_github_csv = os.path.join(ruta_local_data, pln_datos_github_csv)\n",
        "\n",
        "coleccion = []        # Mantenemos esta lista para el vectorizador (Secci√≥n 8)\n",
        "datos_procesados = []  # Nueva lista para estructurar el CSV extendido\n",
        "c = 0\n",
        "\n",
        "# --- CONTROL DE SEGURIDAD: Verificar si el archivo ya existe ---\n",
        "if os.path.exists(ruta_pln_datos_github_csv):\n",
        "    print(f\"‚úÖ El archivo '{pln_datos_github_csv}' ya existe.\")\n",
        "    print(\"üì• Cargando datos procesados previos para reconstruir la colecci√≥n...\")\n",
        "\n",
        "    # Cargamos el archivo existente para recuperar la 'coleccion' necesaria para el M√≥dulo 8\n",
        "    df_existente = pd.read_csv(ruta_pln_datos_github_csv)\n",
        "    coleccion = df_existente['Comentario Preprocesado'].astype(str).tolist()\n",
        "    c = len(coleccion)\n",
        "    print(f\"‚úÖ Colecci√≥n reconstruida con {c} documentos.\")\n",
        "\n",
        "else:\n",
        "    print(\"‚è≥ Iniciando preprocesado y estructuraci√≥n de datos...\")\n",
        "\n",
        "    # Usamos iterrows para tener acceso a la fila completa\n",
        "    for index, row in data.iterrows():\n",
        "        doc = row['comentarios']\n",
        "\n",
        "        # 1. Filtro: Ignorar comentarios del bot\n",
        "        if isinstance(doc, str) and doc.strip().lower().startswith('/ocabot'):\n",
        "            continue\n",
        "\n",
        "        # 2. Ejecuci√≥n del Preprocesado\n",
        "        res = preprocesado(doc)\n",
        "\n",
        "        # 3. Validaci√≥n y Guardado\n",
        "        if isinstance(res, str) and res.strip():\n",
        "            # A) Guardar en colecci√≥n simple (para TF-IDF posterior)\n",
        "            coleccion.append(res)\n",
        "            c += 1\n",
        "\n",
        "            # B) Guardar fila completa para el nuevo CSV\n",
        "            datos_procesados.append({\n",
        "                'tipo': row['tipo'],\n",
        "                'numero': row['numero'],\n",
        "                'titulo': row['titulo'],\n",
        "                'descripcion': row['descripcion'],\n",
        "                'comentarios': doc,  # Original\n",
        "                'Comentario Preprocesado': res, # Salida de la funci√≥n\n",
        "                'Vector FT-IDF unigrama': \"\",\n",
        "                'Vector FT-IDF bigrama': \"\",\n",
        "                'Etiqueta: positivo(1) | neutral(0) | negativo(-1)': \"\"\n",
        "            })\n",
        "\n",
        "    print(f'‚úÖ Se procesaron y estructuraron: {c} documentos')\n",
        "\n",
        "    # --- CREACI√ìN Y SUBIDA DEL NUEVO ARCHIVO CSV ---\n",
        "    if datos_procesados:\n",
        "        df_pln = pd.DataFrame(datos_procesados)\n",
        "\n",
        "        # Guardar localmente en la ruta del repositorio\n",
        "        df_pln.to_csv(ruta_pln_datos_github_csv, index=False, encoding='utf-8-sig')\n",
        "        print(f\"üìÑ Archivo '{pln_datos_github_csv}' generado exitosamente en: {ruta_pln_datos_github_csv}\")\n",
        "\n",
        "        # Sincronizamos a GitHub usando la funci√≥n modular\n",
        "        sincronizar_con_github(ruta_local_data, [pln_datos_github_csv, 'log_file.txt'], \"Add NLP Dataset and Logs (Preprocessed)\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No se generaron datos v√°lidos tras el preprocesado.\")\n",
        "\n",
        "# Validaci√≥n visual\n",
        "print(\"\\n--- Muestra de los primeros 5 elementos de la colecci√≥n ---\")\n",
        "print(coleccion[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VIBF2K4lPxy",
        "outputId": "69da46e0-dd11-4b61-8eee-a9d6255b2779"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Iniciando preprocesado y estructuraci√≥n de datos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-428688763.py:404: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  timestamp = datetime.datetime.utcnow().isoformat()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Se procesaron y estructuraron: 915 documentos\n",
            "üìÑ Archivo 'pln_datos_github.csv' generado exitosamente en local.\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main b337885] Add NLP Dataset and Logs (Preprocessed) (2026-02-10 20:30)\n",
            " 2 files changed, 20025 insertions(+), 915 deletions(-)\n",
            "üöÄ Enviando 2 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 9, done.\n",
            "Counting objects: 100% (9/9), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (5/5), 31.94 KiB | 414.00 KiB/s, done.\n",
            "Total 5 (delta 3), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   3c5e0b0..b337885  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "\n",
            "--- Muestra de los primeros 5 elementos preprocesados ---\n",
            "['tratar', 'poder comprobar problema reproducir odoo utilizar m√≥dulo l10n_es_aeat_mod190 rama generar fichero modelo odoo ejercicio sede electr√≥nico aeat devolver error similar relacionado falta campo obligatorio correspondiente prestaci√≥n jubilaci√≥n viudedad pensi√≥n incapacidad percepci√≥n asimilada requerir aeat ejercicio actualmente dicho campo parecer contemplado rama m√≥dulo provocar fichero generado v√°lir importaci√≥n campo incorporar rama considerar backport cambio permitir mantener compatibilidad modelo requisito aeat ejercicio gracias trabajo soporte', 'soluci√≥n pasar cambio ambos rama cuesti√≥n estar interesado financiar hacer esperar hacer funcionar software abierto contribuir voluntariamente ideal contribuir parche hacer versi√≥n posible exigir hacer parche poner versi√≥n intermedio soler pedir llevar versi√≥n superior mantener sincronizado caso rev√©s haber poner versi√≥n disponible estar versi√≥n anterior mayor√≠a trabajo faltar empuj√≥n anim√°is', 'pedrobaeza gracias aclaraci√≥n poner backport cambio rama cubrir requisito ejercicio intentar gracias cara sonreir ligeramente', 'hola agradecer alguien confirmar problema verifactu v17 buscar raz√≥n funcionar correctamente v16 migrar v17 aparecer error encontrar gracias']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 8. VECTORIZACI√ìN TF-IDF\n",
        "# ==========================================\n",
        "\n",
        "tfidf_vectorizer_unigramas_joblib = \"tfidf_vectorizer_unigramas.joblib\"\n",
        "tfidf_vectorizer_bigramas_joblib = \"tfidf_vectorizer_bigramas.joblib\"\n",
        "\n",
        "ruta_tfidf_vectorizer_unigramas_joblib = os.path.join(ruta_local_data, tfidf_vectorizer_unigramas_joblib)\n",
        "ruta_tfidf_vectorizer_bigramas_joblib = os.path.join(ruta_local_data, tfidf_vectorizer_bigramas_joblib)\n",
        "\n",
        "# --- CONTROL DE SEGURIDAD: Verificar si los modelos ya existen ---\n",
        "if os.path.exists(ruta_tfidf_vectorizer_unigramas_joblib) and os.path.exists(ruta_tfidf_vectorizer_bigramas_joblib):\n",
        "    print(f\"‚úÖ Los modelos vectorizadores ya existen en la carpeta data.\")\n",
        "    print(\"üì• Cargando modelos persistidos en lugar de entrenar nuevos...\")\n",
        "\n",
        "    vectorizer_unigramas = joblib.load(ruta_tfidf_vectorizer_unigramas_joblib)\n",
        "    vectorizer_bigramas = joblib.load(ruta_tfidf_vectorizer_bigramas_joblib)\n",
        "\n",
        "    if coleccion:\n",
        "        X_tfidf_unigramas = vectorizer_unigramas.transform(coleccion)\n",
        "        X_tfidf_bigramas = vectorizer_bigramas.transform(coleccion)\n",
        "        print(\"‚úÖ Matrices TF-IDF reconstruidas desde los archivos cargados.\")\n",
        "else:\n",
        "    # Par√°metros recomendados para repos Git\n",
        "    vectorizer_unigramas = TfidfVectorizer(\n",
        "        analyzer=\"word\",\n",
        "        ngram_range=(1,1),   # unigramas + bigramas; usar (1,1) si solo unigramas\n",
        "        min_df=2,            # ignora t√©rminos que aparecen en menos de 2 documentos\n",
        "        max_df=0.9,          # ignora t√©rminos que aparecen en >90% de docs\n",
        "        use_idf=True,\n",
        "        smooth_idf=True,\n",
        "        norm=\"l2\"\n",
        "    )\n",
        "\n",
        "    vectorizer_bigramas = TfidfVectorizer(\n",
        "        analyzer=\"word\",\n",
        "        ngram_range=(2,2),   # unigramas + bigramas; usar (1,1) si solo unigramas\n",
        "        min_df=2,            # ignora t√©rminos que aparecen en menos de 2 documentos\n",
        "        max_df=0.9,          # ignora t√©rminos que aparecen en >90% de docs\n",
        "        use_idf=True,\n",
        "        smooth_idf=True,\n",
        "        norm=\"l2\"\n",
        "    )\n",
        "\n",
        "    if coleccion:\n",
        "        # Fit y transformar la colecci√≥n completa (IDF se calcula aqu√≠)\n",
        "        X_tfidf_unigramas = vectorizer_unigramas.fit_transform(coleccion)  # --- RF‚Äì03 Representaci√≥n del texto --- el modelo TF‚ÄìIDF (unigramas)\n",
        "        print(\"Matriz TF-IDF_unigramas:\", X_tfidf_unigramas.shape)\n",
        "        X_tfidf_bigramas = vectorizer_bigramas.fit_transform(coleccion)  # --- RF‚Äì03 Representaci√≥n del texto --- el modelo TF‚ÄìIDF (bigramas)\n",
        "        print(\"Matriz TF-IDF_bigramas:\", X_tfidf_bigramas.shape)\n",
        "\n",
        "        # AJUSTE: Guardado directo en la ruta local para compatibilidad modular\n",
        "        joblib.dump(vectorizer_unigramas, ruta_tfidf_vectorizer_unigramas_joblib) # --- RF‚Äì03 Representaci√≥n del texto --- matrices dispersas adecuadas para tareas de PLN.\n",
        "        joblib.dump(vectorizer_bigramas, ruta_tfidf_vectorizer_bigramas_joblib) # --- RF‚Äì03 Representaci√≥n del texto --- matrices dispersas adecuadas para tareas de PLN.\n",
        "\n",
        "        sincronizar_con_github(ruta_local_data, [tfidf_vectorizer_unigramas_joblib, tfidf_vectorizer_bigramas_joblib], \"Add TF-IDF Vectorizer Models (Unigrams/Bigrams)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMJWRF3PnTCm",
        "outputId": "68ebad15-74dc-4529-b521-ebdf7b240dd0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz TF-IDF_unigramas: (915, 1546)\n",
            "Matriz TF-IDF_unigramas: (915, 1574)\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main b46948a] Add TF-IDF Vectorizer Models (Unigrams/Bigrams) (2026-02-10 20:14)\n",
            " 2 files changed, 0 insertions(+), 0 deletions(-)\n",
            " rewrite data/tfidf_vectorizer_bigramas.joblib (96%)\n",
            " rewrite data/tfidf_vectorizer_unigramas.joblib (97%)\n",
            "üöÄ Enviando 2 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 9, done.\n",
            "Counting objects: 100% (9/9), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (5/5), 30.19 KiB | 4.31 MiB/s, done.\n",
            "Total 5 (delta 1), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   ef5be8b..b46948a  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 9. VECTORIZACI√ìN DE LA COLECCI√ìN\n",
        "# ==========================================\n",
        "\n",
        "try:\n",
        "    print(f\"üìÇ Preparando persistencia en el repositorio: {DEST_REPO_NAME}\")\n",
        "\n",
        "    # 1. Sincronizar repositorio local\n",
        "    inicializar_repositorio()\n",
        "\n",
        "    # Definimos la ruta del repositorio como base √∫nica\n",
        "    pln_datos_github_csv = 'pln_datos_github.csv'\n",
        "\n",
        "    ruta_pln_datos_github_csv = os.path.join(ruta_local_data, pln_datos_github_csv)\n",
        "\n",
        "    # 2. Cargar el CSV (Prioridad: Versi√≥n de GitHub para no perder datos previos)\n",
        "    if os.path.exists(ruta_pln_datos_github_csv):\n",
        "        df_pln = pd.read_csv(ruta_pln_datos_github_csv)\n",
        "        print(\"   ...Cargando versi√≥n desde el repositorio local.\")\n",
        "    elif os.path.exists(f\"/content/{pln_datos_github_csv}\"):\n",
        "        df_pln = pd.read_csv(f\"/content/{pln_datos_github_csv}\")\n",
        "        print(\"   ...Cargando versi√≥n desde ra√≠z (migrando al repo).\")\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"No se encontr√≥ el archivo '{pln_datos_github_csv}' en ninguna ubicaci√≥n.\")\n",
        "\n",
        "    # --- L√ìGICA DE EXTRACCI√ìN DE PALABRAS Y PESOS ---\n",
        "\n",
        "    vocab_uni = vectorizer_unigramas.get_feature_names_out()\n",
        "    vocab_bi = vectorizer_bigramas.get_feature_names_out()\n",
        "\n",
        "    def matriz_a_diccionario(matriz_fila, vocabulario):\n",
        "        \"\"\"Convierte una fila de matriz TF-IDF en un diccionario {palabra: peso} limpio\"\"\"\n",
        "        indices_no_cero = matriz_fila.nonzero()[1]\n",
        "        return {vocabulario[i]: round(float(matriz_fila[0, i]), 4) for i in indices_no_cero}\n",
        "\n",
        "    print(\"   ...Transformando matrices a formato {palabra: peso}\")\n",
        "\n",
        "    dict_unigramas = []\n",
        "    dict_bigramas = []\n",
        "\n",
        "    for i in range(len(coleccion)):\n",
        "        d_uni = matriz_a_diccionario(X_tfidf_unigramas[i], vocab_uni)\n",
        "        d_bi = matriz_a_diccionario(X_tfidf_bigramas[i], vocab_bi)\n",
        "\n",
        "        dict_unigramas.append(str(d_uni))\n",
        "        dict_bigramas.append(str(d_bi))\n",
        "\n",
        "    # 4. Actualizaci√≥n de columnas\n",
        "    df_pln['Vector FT-IDF unigrama'] = dict_unigramas\n",
        "    df_pln['Vector FT-IDF bigrama'] = dict_bigramas\n",
        "\n",
        "    # 5. GUARDADO Y SUBIDA (SOLUCI√ìN AL DUPLICADO)\n",
        "    # Guardamos EXCLUSIVAMENTE en la ruta del repositorio\n",
        "    df_pln.to_csv(ruta_pln_datos_github_csv, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    # Definimos los archivos usando sus rutas completas dentro del repo\n",
        "    mensaje = \"Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados\"\n",
        "\n",
        "    # Llamada a la funci√≥n de sincronizaci√≥n\n",
        "    sincronizar_con_github(ruta_local_data, [pln_datos_github_csv], mensaje)\n",
        "\n",
        "    print(f\"‚úÖ Proceso completado. Archivo guardado en: {ruta_pln_datos_github_csv}\")\n",
        "    print(\"üöÄ Cambios enviados a GitHub sin duplicados en la ra√≠z.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error en el M√≥dulo 10: {e}\")"
      ],
      "metadata": {
        "id": "tmMvffauWxTU",
        "outputId": "d38f47d0-4668-4a09-ea80-f6354bae6100",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Preparando persistencia en el repositorio: U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            "/content\n",
            "üîÑ Sincronizando repositorio...\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n",
            "/content\n",
            "üìÇ Carpeta de datos lista en: /content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            "   ...Cargando versi√≥n desde el repositorio local.\n",
            "   ...Transformando matrices a formato {palabra: peso}\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n",
            "Everything up-to-date\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Proceso completado. Archivo guardado en: /content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data/pln_datos_github.csv\n",
            "üöÄ Cambios enviados a GitHub sin duplicados en la ra√≠z.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ================================================\n",
        "# 10. ETIQUETADO DE PARA AN√ÅLISIS DE SENTIMIENTOS\n",
        "# ================================================\n",
        "\n",
        "# 1. Cargar el archivo como pln_coleccion\n",
        "ruta_pln_datos_github_csv = '/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data/pln_datos_github.csv'\n",
        "pln_datos_github_csv = 'pln_datos_github.csv'\n",
        "pln_coleccion = pd.read_csv(ruta_pln_datos_github_csv)\n",
        "\n",
        "col_comentario = 'Comentario Preprocesado'\n",
        "col_etiqueta = 'Etiqueta: positivo(1) | neutral(0) | negativo(-1)'\n",
        "\n",
        "# Limpieza t√©cnica: Asegurar que los vac√≠os sean reconocidos como NaN\n",
        "# Esto soluciona el problema de si la primera fila tiene espacios invisibles\n",
        "pln_coleccion[col_etiqueta] = pd.to_numeric(pln_coleccion[col_etiqueta], errors='coerce')\n",
        "\n",
        "# 2. Verificar pendientes\n",
        "pendientes_mask = pln_coleccion[col_etiqueta].isna()\n",
        "if not pendientes_mask.any():\n",
        "    print(\"================================\")\n",
        "    print(\"      Etiquetado Completado     \")\n",
        "    print(\"================================\")\n",
        "else:\n",
        "    print(f\"Iniciando... Filas pendientes: {pendientes_mask.sum()}\\n\")\n",
        "\n",
        "    # 3. Bucle para recorrer la colecci√≥n\n",
        "    for index, row in pln_coleccion.iterrows():\n",
        "\n",
        "        # Validaci√≥n robusta: verifica si es NaN real\n",
        "        if pd.isna(row[col_etiqueta]):\n",
        "            pln_doc = row[col_comentario]\n",
        "\n",
        "            print(\"-\" * 50)\n",
        "            print(f\"ID Fila: {index}\") # Esto te confirmar√° si empieza en 0 o 1\n",
        "            print(f\"Comentario actual: {pln_doc}\")\n",
        "\n",
        "            continuar_proceso = True\n",
        "            while True:\n",
        "                entrada = input(\"Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: \").strip()\n",
        "\n",
        "                if entrada == '#':\n",
        "                    continuar_proceso = False\n",
        "                    break\n",
        "\n",
        "                if entrada in ['1', '0', '-1']:\n",
        "                    etiqueta_pln_doc = int(entrada)\n",
        "\n",
        "                    # --- GUARDADO DENTRO DEL WHILE ---\n",
        "                    pln_coleccion.at[index, col_etiqueta] = etiqueta_pln_doc\n",
        "                    pln_coleccion.to_csv(ruta_pln_datos_github_csv, index=False)\n",
        "\n",
        "                    pln_coleccion.to_csv(ruta_pln_datos_github_csv, index=False, encoding='utf-8-sig')\n",
        "                    mensaje_github = \"Etiqueta Actualizada\"\n",
        "\n",
        "                    sincronizar_con_github(ruta_local_data, [pln_datos_github_csv], mensaje)\n",
        "\n",
        "                    print(f\"‚úÖ Fila {index} sincronizada.\")\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"‚ö†Ô∏è Entrada inv√°lida.\")\n",
        "\n",
        "            if not continuar_proceso:\n",
        "                print(\"\\nProceso detenido.\")\n",
        "                break\n",
        "\n",
        "    if pln_coleccion[col_etiqueta].isna().sum() == 0:\n",
        "        print(\"\\n================================\")\n",
        "        print(\"      Etiquetado Completado     \")\n",
        "        print(\"================================\")"
      ],
      "metadata": {
        "id": "Xf_BriZISbSb",
        "outputId": "a4da8106-3fac-4ec3-f4c0-70720ac7f881",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando... Filas pendientes: 914\n",
            "\n",
            "--------------------------------------------------\n",
            "ID Fila: 1\n",
            "Comentario actual: poder comprobar problema reproducir odoo utilizar m√≥dulo l10n_es_aeat_mod190 rama generar fichero modelo odoo ejercicio sede electr√≥nico aeat devolver error similar relacionado falta campo obligatorio correspondiente prestaci√≥n jubilaci√≥n viudedad pensi√≥n incapacidad percepci√≥n asimilada requerir aeat ejercicio actualmente dicho campo parecer contemplado rama m√≥dulo provocar fichero generado v√°lir importaci√≥n campo incorporar rama considerar backport cambio permitir mantener compatibilidad modelo requisito aeat ejercicio gracias trabajo soporte\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 0\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main eb64e09] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:16)\n",
            " 1 file changed, 2 insertions(+), 2 deletions(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 4 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (4/4), 5.20 KiB | 888.00 KiB/s, done.\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "   6db7957..95030bb  main       -> origin/main\n",
            "\u001b[KSuccessfully rebased and updated refs/heads/main.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 566 bytes | 566.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   95030bb..2d784e2  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 1 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 2\n",
            "Comentario actual: soluci√≥n pasar cambio ambos rama cuesti√≥n estar interesado financiar hacer esperar hacer funcionar software abierto contribuir voluntariamente ideal contribuir parche hacer versi√≥n posible exigir hacer parche poner versi√≥n intermedio soler pedir llevar versi√≥n superior mantener sincronizado caso rev√©s haber poner versi√≥n disponible estar versi√≥n anterior mayor√≠a trabajo faltar empuj√≥n anim√°is\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 1\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main b883c68] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:17)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 547 bytes | 547.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   2d784e2..b883c68  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 2 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 3\n",
            "Comentario actual: pedrobaeza gracias aclaraci√≥n poner backport cambio rama cubrir requisito ejercicio intentar gracias cara sonreir ligeramente\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 1\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main 0af3321] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:24)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 540 bytes | 540.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   b883c68..0af3321  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 3 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 4\n",
            "Comentario actual: hola agradecer alguien confirmar problema verifactu v17 buscar raz√≥n funcionar correctamente v16 migrar v17 aparecer error encontrar gracias\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 0\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main 1128984] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:25)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 537 bytes | 537.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   0af3321..1128984  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 4 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 5\n",
            "Comentario actual: poder solucionar √©l v12 existir core odoo reconciliaci√≥n v14 m√≥dulo oca m√≥dulo llegar v18 desplegar bbdd actualizado mostrar m√≥dulo reconciliaci√≥n alguien servir soluci√≥n gracias\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 1\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main b5c5d3c] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:25)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 561 bytes | 561.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   1128984..b5c5d3c  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 5 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 6\n",
            "Comentario actual: pedrobaeza cambio llevasteis cabo causar ralentizaci√≥n error utilizar grupo impuesto caso dua concretamente dar feedback\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: -1\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main 817c320] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:26)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 564 bytes | 564.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   b5c5d3c..817c320  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 6 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 7\n",
            "Comentario actual: pedrobaeza pudiste echar √©l ojo comentario incidencia gracias\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 0\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main 87ea434] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:29)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 4 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (4/4), 1.39 KiB | 237.00 KiB/s, done.\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "   817c320..dd9f30c  main       -> origin/main\n",
            "\u001b[KSuccessfully rebased and updated refs/heads/main.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 557 bytes | 557.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   dd9f30c..c3fc84a  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 7 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 8\n",
            "Comentario actual: sentir\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 0\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main 8940714] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:29)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 549 bytes | 549.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   c3fc84a..8940714  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 8 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 9\n",
            "Comentario actual: pedrobaeza poder echar √©l ojo proponer parche directamente\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 1\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main 4eacb99] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:29)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 555 bytes | 555.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   8940714..4eacb99  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 9 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 10\n",
            "Comentario actual: poder proponer parche agradecer a√±o desbordado\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 1\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main b05f240] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:30)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 541 bytes | 541.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   4eacb99..b05f240  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 10 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 11\n",
            "Comentario actual: dejar issue abierto referencia\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 0\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main 02aa4c8] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:34)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 548 bytes | 548.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   b05f240..02aa4c8  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 11 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 12\n",
            "Comentario actual: pedrobaeza dejar issue abierto resto usuario tener facilidad encontrar traza etc. plantear refactoring cerrar gracias\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 1\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main 3355c7c] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:34)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 538 bytes | 538.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   02aa4c8..3355c7c  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 12 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 13\n",
            "Comentario actual: faltar m√≥dulo l10n_es_sii_reav a√±adir mapeo corresponder tratar clave adecuado posici√≥n fiscal\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 0\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main f4bb426] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:34)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 554 bytes | 554.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   3355c7c..f4bb426  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 13 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 14\n",
            "Comentario actual: factura rappel rectificar factura introducido odoo ejemplo cambio software pasar enviar facturasrectificada deber parche\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 0\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main a60f80b] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:35)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 556 bytes | 556.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   f4bb426..a60f80b  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 14 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 15\n",
            "Comentario actual: parche enviar √©l facturasrectificadas marcar dise√±o registro obligatorio enviar aceptar enviar verifactu tipofactura r1 tiporectificativa i facturasrectificada enviar verifactu tipofactura r1 tiporectificativa false descripcionoperacion enviar m√≥dulo verifactu aeat rechazar realmente enviar cron error visible\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: -1\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main 1c292c2] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:35)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 558 bytes | 558.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   a60f80b..1c292c2  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 15 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 16\n",
            "Comentario actual: hola instalaci√≥n odoo verifactu usuario mala costumbre verifactu factura rectificativo directamente crear √©l factura venta original resultado comentar issue factura rectificativo creado soluci√≥n entender esperar verifactu faltar meter √©l bd soluci√≥n gracia\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: -1\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main 2728712] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:38)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 540 bytes | 540.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   1c292c2..2728712  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 16 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 17\n",
            "Comentario actual: hola √∫nicamente confirmar introducir bd reversed_entry_id factura original relacionado rectificativo solucionar problema puntual entender soluci√≥n definitivo verifactu instalado habilitado permitir usuario crear factura rectificativa directamente permitir cancelaci√≥n factura saludo gracia\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 0\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main 71da332] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:39)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 545 bytes | 545.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   2728712..71da332  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 17 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 18\n",
            "Comentario actual: validador funcionar correctamente xsd cumplir factura subir face haber probar subir\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 1\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main d7262d9] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:39)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 547 bytes | 547.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   71da332..d7262d9  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 18 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 19\n",
            "Comentario actual: error intentar subir\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: -1\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main 5d454c2] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:39)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 549 bytes | 549.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   d7262d9..5d454c2  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 19 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 20\n",
            "Comentario actual: experimento sistema face etobella tener problema\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: -1\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main 30e08d7] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:40)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 544 bytes | 544.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   5d454c2..30e08d7  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 20 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 21\n",
            "Comentario actual: integraci√≥n directo ver error cliente ver error quejar etiqueta cnocnae definido deber vac√≠o teor√≠a rellenar vaciar autom√°ticamente\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: -1\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main 0cde5dd] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:40)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 542 bytes | 542.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   30e08d7..0cde5dd  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 21 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 22\n",
            "Comentario actual: etobella quejar etiqueta vacia fix vacia poner fichero dejar subir corregir m√≥dulo\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 1\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main beb5684] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:41)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 542 bytes | 542.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   0cde5dd..beb5684  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 22 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 23\n",
            "Comentario actual: manuelcalerosoli limpieza autom√°ticamente tiempo fichero firmado odoo deber salir limpio\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 1\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main ef4ee31] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:41)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 544 bytes | 544.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   beb5684..ef4ee31  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 23 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 24\n",
            "Comentario actual: cliente exportar firmar salir limpio\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 1\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main cc84955] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:54)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 4 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (4/4), 2.51 KiB | 197.00 KiB/s, done.\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "   ef4ee31..8b0e037  main       -> origin/main\n",
            "\u001b[KSuccessfully rebased and updated refs/heads/main.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 547 bytes | 547.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   8b0e037..b4f4f49  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 24 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 25\n",
            "Comentario actual: usar complica vida ver necesario poder proponer pr cara gui√±ar ojo\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 1\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main 2c51931] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:55)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 541 bytes | 541.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   b4f4f49..2c51931  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 25 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 26\n",
            "Comentario actual: deber backport\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 0\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main 9a80f60] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:56)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 547 bytes | 547.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   2c51931..9a80f60  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 26 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 27\n",
            "Comentario actual: ver bug interesante crear diario venta generar alerta tipo favor revise activar comunicaci√≥n verifactu diario caso necesitar registrar importar odoo factura venta generar sif comunicar verifactu sistema\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 1\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main 72f6080] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:56)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 547 bytes | 547.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   9a80f60..72f6080  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 27 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 28\n",
            "Comentario actual: sif cumplir normativa permitir crear factura check activado cumplir reglamento facturacion preocupaci√≥n\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 1\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main bc0e741] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:57)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 549 bytes | 549.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   72f6080..bc0e741  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 28 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 29\n",
            "Comentario actual: casu√≠stica poder justificar enviar veri factu puerta abierto diario caja b almumu anmarmo1 soniaviciana record√°is raz√≥n inicial habilitar veri factu diario mimetizar sii plantear √©l posici√≥n fiscal\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 0\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main 40b7ac1] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:57)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 548 bytes | 548.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   bc0e741..40b7ac1  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 29 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 30\n",
            "Comentario actual: disculpa conven√≠s proceder venir colaci√≥n casu√≠stica tener destinatario operaci√≥n emitir factura nombre emisor destinatario enviar aeat generar sif autofactura enviar emisor necesitar introducir odoo factura contabilizar √©l factura enviar serie n√∫mero limitar modificar elemento registro account.move pertenecer diario concreto generar factura modificaci√≥n reporte\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 0\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main 5480584] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 21:58)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 546 bytes | 546.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   40b7ac1..5480584  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 30 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 31\n",
            "Comentario actual: poner escenario real empresa sector el√©ctrico utilizar odoo erp operativa general contabilidad compra facturaci√≥n etc. subcontratar sif externo emisi√≥n determinado factura nombre sif externo generar serie numeraci√≥n remitir factura verifactu cumplir obligaci√≥n t√©cnico env√≠o establecido reglamento contabilidad consolidado odoo empresa importar peri√≥dicamente factura emitido sistema externo existir factura odoo iva libro modelo fiscal conciliaci√≥n deber reenviar √©l verifactu env√≠o correctamente sif motivo ver l√≥gico m√≥dulo oca permitir configurar diario registrar integren factura externo verifactu desactivado evitar duplicidad aeat punto vista configuraci√≥n diario error permitir cubrir escenario empresa facturo sif centralizar contabilidad odoo contexto existir sif diferenciado sif externo emitir responsable enviar verifactu generar odoo actuar sif √∫nicamente factura emitido efectivamente odoo diario verifactu emitir simplemente contabilizar factura originado sistema coincido pedro flexibilidad malutilizar √©l crear diario opaco entender riesgo pr√°cticamente erp derivar funcionalidad control interno proceso empresa\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 0\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main e604e43] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 22:00)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 542 bytes | 542.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   5480584..e604e43  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 31 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 32\n",
            "Comentario actual: planteamiento permitir emitir factura margen reglamento viable\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 0\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main e2e4866] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 22:00)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 541 bytes | 541.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   e604e43..e2e4866  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 32 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 33\n",
            "Comentario actual: faq desarrollador aeat .pdf punto importaci√≥n factura pista tema poner extracto sistema empresario efectivamente factura clase producido sif producido sif empresario delegar facturaci√≥n factura naturalmente volver imprimir qr volver enviar √©l sede electr√≥nico aeat ambos funcionalidad sif empresa materialmente emitir\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 0\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main 00b1c08] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 22:01)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 543 bytes | 543.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   e2e4866..00b1c08  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 33 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 34\n",
            "Comentario actual: m√≥dulo odoo sa ejemplo permitir desconectar verifactu diario venta verifactu activado\n",
            "Etiqueta: positivo(1) | neutral(0) | negativo(-1) o '#' para salir: 0\n",
            "/content/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J/data\n",
            "[main af7eb8d] Update: Vectores FT-IDF unigrama, Vector FT-IDF bigrama, y pln_datos_github.csv actualizados (2026-02-10 22:02)\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "üöÄ Enviando 1 archivo(s) a GitHub...\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 545 bytes | 545.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J.git\n",
            "   00b1c08..af7eb8d  main -> main\n",
            "‚úÖ Sincronizaci√≥n exitosa.\n",
            "/content\n",
            "‚úÖ Fila 34 sincronizada.\n",
            "--------------------------------------------------\n",
            "ID Fila: 35\n",
            "Comentario actual: m√≥dulo odoo sa bloquear diario venta hash odoo cuestion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================================\n",
        "# 11. SECCI√ìN DE PRUEBAS\n",
        "# ==========================================\n",
        "\n",
        "\n",
        "# Vector del documento i (sparse row)\n",
        "i = 1\n",
        "vec_i = X_tfidf_unigramas[i]  # scipy.sparse.csr_matrix (1, n_features)\n",
        "\n",
        "# Obtener nombres de features (t√©rminos / n-gramas)\n",
        "features = vectorizer_unigramas.get_feature_names_out()\n",
        "\n",
        "# Para ver los top-k t√©rminos con mayor peso en doc i:\n",
        "k = 10\n",
        "row = vec_i.tocoo()\n",
        "top_idx = np.argsort(row.data)[-k:][::-1]  # √≠ndices en row.data ordenados por peso\n",
        "top_terms = [(features[row.col[idx]], row.data[idx]) for idx in top_idx]\n",
        "print(\"Top terms doc (unigramas)\", i, top_terms)\n",
        "\n",
        "# 1. Definir la ruta del modelo dentro del repositorio clonado\n",
        "# DEST_REPO_NAME viene de tu Celda de Configuraci√≥n Com√∫n\n",
        "ruta_modelo_github = f\"/content/{DEST_REPO_NAME}/data/tfidf_vectorizer_unigramas.joblib\"\n",
        "\n",
        "# 2. Cargar el vectorizador desde GitHub (repo local)\n",
        "try:\n",
        "    if os.path.exists(ruta_modelo_github):\n",
        "        vectorizer = joblib.load(ruta_modelo_github)\n",
        "        print(\"‚úÖ Modelo cargado exitosamente desde GitHub.\")\n",
        "    else:\n",
        "        print(\"‚ùå Error: El modelo no se encuentra en la ruta del repositorio. ¬øYa hiciste el push?\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error al cargar el modelo: {e}\")\n",
        "\n",
        "# 3. Uso del modelo cargado\n",
        "nuevo_doc = \"error al ejecutar test de integraci√≥n en CI\"\n",
        "nuevo_pre = preprocesado(nuevo_doc)  # usar tu funci√≥n\n",
        "\n",
        "# Transformar usando el vectorizador cargado\n",
        "vec_nuevo = vectorizer.transform([nuevo_pre])  # no fit, solo transform\n",
        "print(\"Matriz TF-IDF del nuevo doc:\", vec_nuevo.shape)\n",
        "print(vec_nuevo)\n",
        "\n",
        "# Obtener los nombres de las palabras\n",
        "nombres = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Ver qu√© palabras corresponden a los √≠ndices 388 y 635\n",
        "print(f\"Palabra en 388: {nombres[388]}\")\n",
        "print(f\"Palabra en 635: {nombres[635]}\")\n",
        "\n",
        "# 1. Buscar el √≠ndice de la palabra \"error\" en el vocabulario\n",
        "vocabulario = vectorizer.get_feature_names_out()\n",
        "palabra_a_buscar = \"error\"\n",
        "\n",
        "if palabra_a_buscar in vocabulario:\n",
        "    # Obtener el √≠ndice (columna)\n",
        "    indice = list(vocabulario).index(palabra_a_buscar)\n",
        "    print(f\"‚úÖ La palabra '{palabra_a_buscar}' est√° en el vocabulario en el √≠ndice: {indice}\")\n",
        "\n",
        "    # 2. Ver el peso de esa palabra en el 'nuevo_doc' que transformaste antes\n",
        "    # vec_nuevo es la matriz (1, 1238) que obtuviste en el paso anterior\n",
        "    peso_tfidf = vec_nuevo[0, indice]\n",
        "\n",
        "    if peso_tfidf > 0:\n",
        "        print(f\"üìä Peso TF-IDF de '{palabra_a_buscar}' en el nuevo doc: {peso_tfidf:.4f}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è La palabra existe en el modelo, pero no tiene peso en este documento espec√≠fico (quiz√°s fue filtrada o no estaba en el string original).\")\n",
        "else:\n",
        "    print(f\"‚ùå La palabra '{palabra_a_buscar}' NO existe en el vocabulario del modelo.\")"
      ],
      "metadata": {
        "id": "Hycfq1gzx1i-",
        "outputId": "1ab0321c-3fc2-4f97-987d-7d8bc3430bd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top terms doc (unigramas) 1 [('ejercicio', np.float64(0.3760118860761082)), ('rama', np.float64(0.36829554210209065)), ('aeat', np.float64(0.2643283775347077)), ('campo', np.float64(0.24623013387705966)), ('fichero', np.float64(0.2177532537713971)), ('modelo', np.float64(0.18498330508422126)), ('odoo', np.float64(0.1474602982086119)), ('prestaci√≥n', np.float64(0.14047405943799587)), ('sede', np.float64(0.14047405943799587)), ('generado', np.float64(0.13560110981518958))]\n",
            "‚úÖ Modelo cargado exitosamente desde GitHub.\n",
            "Matriz TF-IDF del nuevo doc: (1, 1541)\n",
            "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 5 stored elements and shape (1, 1541)>\n",
            "  Coords\tValues\n",
            "  (0, 215)\t0.4877058348683418\n",
            "  (0, 479)\t0.46064560040232533\n",
            "  (0, 526)\t0.28017024345813835\n",
            "  (0, 782)\t0.5710506569384148\n",
            "  (0, 1417)\t0.38125376241575293\n",
            "Palabra en 388: dec√≠s\n",
            "Palabra en 635: flexibilidad\n",
            "‚úÖ La palabra 'error' est√° en el vocabulario en el √≠ndice: 526\n",
            "üìä Peso TF-IDF de 'error' en el nuevo doc: 0.2802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1624110909.py:404: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  timestamp = datetime.datetime.utcnow().isoformat()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================================\n",
        "# 12. REINICIAR CONEXI√ìN GTIHUB\n",
        "# ==========================================\n",
        "\n",
        "# Configurar la estrategia de reconciliaci√≥n\n",
        "!git -C /content/{DEST_REPO_NAME} config pull.rebase false\n",
        "\n",
        "# Forzar una limpieza y descarga de la versi√≥n actual de GitHub\n",
        "try:\n",
        "    print(\"üîÑ Sincronizando repositorio...\")\n",
        "    !git -C /content/{DEST_REPO_NAME} fetch origin\n",
        "    !git -C /content/{DEST_REPO_NAME} reset --hard origin/main # O 'master' seg√∫n tu rama\n",
        "    print(\"‚úÖ Repositorio sincronizado y limpio.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error al sincronizar: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjCMjl3oZxgm",
        "outputId": "a918d38f-de12-4acb-dfce-1eafa6d620b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Sincronizando repositorio...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 4 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (4/4), 1.67 KiB | 214.00 KiB/s, done.\n",
            "From https://github.com/jpmachinelearning/U4_S16_Trabajo_Final_2P_PLAZA_A-PADILLA_J\n",
            "   1156f44..a14135f  main       -> origin/main\n",
            "HEAD is now at a14135f Created using Colab\n",
            "‚úÖ Repositorio sincronizado y limpio.\n"
          ]
        }
      ]
    }
  ]
}